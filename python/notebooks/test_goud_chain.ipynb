{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goud Chain API Testing Suite\n",
    "\n",
    "Comprehensive test notebook for all Goud Chain API endpoints with timing metrics and reporting.\n",
    "\n",
    "**Features:**\n",
    "- Create API keys and authenticate\n",
    "- Bulk data submission (configurable batch size)\n",
    "- Collection management and decryption\n",
    "- Blockchain explorer and analytics\n",
    "- Performance metrics with visualizations\n",
    "- Final report generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Adjust these settings before running tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ Configuration ============\n",
    "\n",
    "# API Endpoint (Docker internal network or external)\n",
    "BASE_URL = \"http://localhost:8080\"  # Use this when running in Docker\n",
    "# BASE_URL = \"http://localhost:8080\"  # Use this for external testing\n",
    "\n",
    "# Test Parameters\n",
    "BULK_SUBMISSION_COUNT = 100  # Number of blocks to create in bulk test\n",
    "API_TIMEOUT = 30  # Request timeout in seconds\n",
    "RETRY_ATTEMPTS = 3  # Number of retries for failed requests\n",
    "\n",
    "# Debug Settings\n",
    "VERBOSE_LOGGING = True  # Print detailed logs\n",
    "SHOW_REQUEST_BODIES = False  # Print full request/response bodies\n",
    "\n",
    "# Report Settings\n",
    "EXPORT_TO_CSV = True  # Export results to CSV\n",
    "EXPORT_TO_JSON = True  # Export results to JSON\n",
    "GENERATE_CHARTS = True  # Generate timing charts\n",
    "REPORT_OUTPUT_DIR = \"../scratch/\"  # Where to save reports\n",
    "\n",
    "print(\"✅ Configuration loaded\")\n",
    "print(f\"📡 API Endpoint: {BASE_URL}\")\n",
    "print(f\"🔢 Bulk submission count: {BULK_SUBMISSION_COUNT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup & Utilities\n",
    "\n",
    "Import libraries and define helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import platform\n",
    "import psutil\n",
    "import socket\n",
    "import sys\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Global state storage\n",
    "GLOBAL_STATE = {\n",
    "    \"api_key\": None,\n",
    "    \"account_id\": None,\n",
    "    \"session_token\": None,\n",
    "    \"collection_ids\": [],\n",
    "    \"test_results\": [],\n",
    "    \"timing_data\": {},\n",
    "    \"system_info\": {},\n",
    "    \"server_health_history\": [],\n",
    "    \"failed_dependencies\": set(),\n",
    "}\n",
    "\n",
    "# Configure plotting style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "def capture_system_info() -> Dict[str, Any]:\n",
    "    \"\"\"Capture comprehensive system information\"\"\"\n",
    "    try:\n",
    "        cpu_count = psutil.cpu_count(logical=True)\n",
    "        cpu_count_physical = psutil.cpu_count(logical=False)\n",
    "        memory = psutil.virtual_memory()\n",
    "        disk = psutil.disk_usage('/')\n",
    "        \n",
    "        system_info = {\n",
    "            # System basics\n",
    "            \"hostname\": socket.gethostname(),\n",
    "            \"platform\": platform.platform(),\n",
    "            \"platform_system\": platform.system(),\n",
    "            \"platform_release\": platform.release(),\n",
    "            \"platform_version\": platform.version(),\n",
    "            \"architecture\": platform.machine(),\n",
    "            \"processor\": platform.processor(),\n",
    "            \n",
    "            # CPU\n",
    "            \"cpu_count_logical\": cpu_count,\n",
    "            \"cpu_count_physical\": cpu_count_physical,\n",
    "            \"cpu_frequency_mhz\": psutil.cpu_freq().current if psutil.cpu_freq() else \"N/A\",\n",
    "            \"cpu_percent\": psutil.cpu_percent(interval=1),\n",
    "            \n",
    "            # Memory\n",
    "            \"memory_total_gb\": round(memory.total / (1024**3), 2),\n",
    "            \"memory_available_gb\": round(memory.available / (1024**3), 2),\n",
    "            \"memory_used_gb\": round(memory.used / (1024**3), 2),\n",
    "            \"memory_percent\": memory.percent,\n",
    "            \n",
    "            # Disk\n",
    "            \"disk_total_gb\": round(disk.total / (1024**3), 2),\n",
    "            \"disk_used_gb\": round(disk.used / (1024**3), 2),\n",
    "            \"disk_free_gb\": round(disk.free / (1024**3), 2),\n",
    "            \"disk_percent\": disk.percent,\n",
    "            \n",
    "            # Python environment\n",
    "            \"python_version\": sys.version,\n",
    "            \"python_executable\": sys.executable,\n",
    "            \n",
    "            # Network\n",
    "            \"ip_address\": socket.gethostbyname(socket.gethostname()),\n",
    "            \n",
    "            # Timestamp\n",
    "            \"captured_at\": datetime.now().isoformat(),\n",
    "        }\n",
    "        \n",
    "        # Try to get Docker info if running in container\n",
    "        try:\n",
    "            with open('/proc/1/cgroup', 'r') as f:\n",
    "                system_info[\"running_in_docker\"] = 'docker' in f.read()\n",
    "        except:\n",
    "            system_info[\"running_in_docker\"] = False\n",
    "        \n",
    "        return system_info\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to capture system info: {str(e)}\"}\n",
    "\n",
    "# Capture system info on startup\n",
    "GLOBAL_STATE[\"system_info\"] = capture_system_info()\n",
    "\n",
    "print(\"✅ Libraries imported\")\n",
    "print(\"✅ Global state initialized\")\n",
    "print(\"✅ System information captured\")\n",
    "print(f\"\\n📊 System Overview:\")\n",
    "print(f\"   Platform: {GLOBAL_STATE['system_info'].get('platform_system')} {GLOBAL_STATE['system_info'].get('platform_release')}\")\n",
    "print(f\"   CPU: {GLOBAL_STATE['system_info'].get('cpu_count_logical')} cores @ {GLOBAL_STATE['system_info'].get('cpu_percent')}% usage\")\n",
    "print(f\"   Memory: {GLOBAL_STATE['system_info'].get('memory_available_gb')} GB available / {GLOBAL_STATE['system_info'].get('memory_total_gb')} GB total\")\n",
    "print(f\"   Disk: {GLOBAL_STATE['system_info'].get('disk_free_gb')} GB free / {GLOBAL_STATE['system_info'].get('disk_total_gb')} GB total\")\n",
    "print(f\"   Python: {sys.version.split()[0]}\")\n",
    "print(f\"   Docker: {'Yes' if GLOBAL_STATE['system_info'].get('running_in_docker') else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ Helper Functions ============\n",
    "\n",
    "class ErrorCategory:\n",
    "    \"\"\"Error type classification\"\"\"\n",
    "    CONNECTION_ERROR = \"connection_error\"\n",
    "    TIMEOUT = \"timeout\"\n",
    "    HTTP_ERROR = \"http_error\"\n",
    "    SERVER_CRASH = \"server_crash\"\n",
    "    JSON_PARSE_ERROR = \"json_parse_error\"\n",
    "    AUTHENTICATION_ERROR = \"authentication_error\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "class ServerHealth:\n",
    "    \"\"\"Server health states\"\"\"\n",
    "    ALIVE = \"alive\"\n",
    "    DEGRADED = \"degraded\"\n",
    "    CRASHED = \"crashed\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "class APIClient:\n",
    "    \"\"\"Wrapper for Goud Chain API calls with timing, error handling, and retry logic\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url: str, timeout: int = 30, retry_attempts: int = 3):\n",
    "        self.base_url = base_url.rstrip('/')\n",
    "        self.timeout = timeout\n",
    "        self.retry_attempts = retry_attempts\n",
    "        self.session = requests.Session()\n",
    "    \n",
    "    def _log(self, message: str, level: str = \"INFO\"):\n",
    "        if VERBOSE_LOGGING or level == \"ERROR\":\n",
    "            timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n",
    "            print(f\"[{timestamp}] {level}: {message}\")\n",
    "    \n",
    "    def _categorize_error(self, exception: Exception) -> str:\n",
    "        \"\"\"Categorize exception into error type\"\"\"\n",
    "        if isinstance(exception, requests.exceptions.ConnectionError):\n",
    "            return ErrorCategory.CONNECTION_ERROR\n",
    "        elif isinstance(exception, requests.exceptions.Timeout):\n",
    "            return ErrorCategory.TIMEOUT\n",
    "        elif isinstance(exception, requests.exceptions.HTTPError):\n",
    "            return ErrorCategory.HTTP_ERROR\n",
    "        elif isinstance(exception, json.JSONDecodeError):\n",
    "            return ErrorCategory.JSON_PARSE_ERROR\n",
    "        else:\n",
    "            return ErrorCategory.UNKNOWN\n",
    "    \n",
    "    def check_server_health(self) -> Tuple[str, Dict]:\n",
    "        \"\"\"Check if server is responsive. Returns (health_status, details)\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(f\"{self.base_url}/health\", timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                health_status = ServerHealth.ALIVE\n",
    "                details = {\n",
    "                    \"status\": \"healthy\",\n",
    "                    \"node_id\": data.get(\"node_id\", \"unknown\"),\n",
    "                    \"chain_length\": data.get(\"chain_length\", 0),\n",
    "                    \"peer_count\": data.get(\"peer_count\", 0),\n",
    "                }\n",
    "            else:\n",
    "                health_status = ServerHealth.DEGRADED\n",
    "                details = {\n",
    "                    \"status\": \"degraded\",\n",
    "                    \"http_status\": response.status_code,\n",
    "                    \"error\": response.text[:200]\n",
    "                }\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            health_status = ServerHealth.CRASHED\n",
    "            details = {\"status\": \"crashed\", \"error\": \"Cannot connect to server\"}\n",
    "        except requests.exceptions.Timeout:\n",
    "            health_status = ServerHealth.DEGRADED\n",
    "            details = {\"status\": \"degraded\", \"error\": \"Health check timeout\"}\n",
    "        except Exception as e:\n",
    "            health_status = ServerHealth.UNKNOWN\n",
    "            details = {\"status\": \"unknown\", \"error\": str(e)}\n",
    "        \n",
    "        # Record in history\n",
    "        GLOBAL_STATE[\"server_health_history\"].append({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"health\": health_status,\n",
    "            \"details\": details\n",
    "        })\n",
    "        \n",
    "        return health_status, details\n",
    "    \n",
    "    def request(self, method: str, endpoint: str, data: Optional[Dict] = None, \n",
    "                headers: Optional[Dict] = None, retry: bool = True) -> Tuple[Optional[Dict], float, bool, str, Optional[str]]:\n",
    "        \"\"\"Make HTTP request with timing and retry logic. \n",
    "        Returns (response_data, elapsed_time, success, error_category, stack_trace)\"\"\"\n",
    "        url = f\"{self.base_url}{endpoint}\"\n",
    "        headers = headers or {}\n",
    "        \n",
    "        if data:\n",
    "            headers[\"Content-Type\"] = \"application/json\"\n",
    "        \n",
    "        retry_count = 0\n",
    "        max_retries = self.retry_attempts if retry else 1\n",
    "        last_error = None\n",
    "        last_error_category = None\n",
    "        stack_trace = None\n",
    "        \n",
    "        while retry_count < max_retries:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                self._log(f\"{method} {endpoint} (attempt {retry_count + 1}/{max_retries})\")\n",
    "                \n",
    "                if method == \"GET\":\n",
    "                    response = self.session.get(url, headers=headers, timeout=self.timeout)\n",
    "                elif method == \"POST\":\n",
    "                    response = self.session.post(url, json=data, headers=headers, timeout=self.timeout)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported method: {method}\")\n",
    "                \n",
    "                elapsed = time.time() - start_time\n",
    "                \n",
    "                if response.status_code >= 200 and response.status_code < 300:\n",
    "                    try:\n",
    "                        result = response.json() if response.content else {}\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        self._log(f\"❌ JSON parse error: {str(e)}\", \"ERROR\")\n",
    "                        return {\"error\": \"Invalid JSON response\", \"raw\": response.text[:500]}, elapsed, False, ErrorCategory.JSON_PARSE_ERROR, traceback.format_exc()\n",
    "                    \n",
    "                    self._log(f\"✅ Success ({response.status_code}) in {elapsed:.3f}s\")\n",
    "                    return result, elapsed, True, None, None\n",
    "                else:\n",
    "                    self._log(f\"❌ Failed ({response.status_code}): {response.text[:200]}\", \"ERROR\")\n",
    "                    error_category = ErrorCategory.HTTP_ERROR\n",
    "                    if response.status_code == 401 or response.status_code == 403:\n",
    "                        error_category = ErrorCategory.AUTHENTICATION_ERROR\n",
    "                    return {\"error\": response.text, \"status_code\": response.status_code}, elapsed, False, error_category, None\n",
    "            \n",
    "            except requests.exceptions.ConnectionError as e:\n",
    "                elapsed = time.time() - start_time\n",
    "                last_error = e\n",
    "                last_error_category = ErrorCategory.CONNECTION_ERROR\n",
    "                stack_trace = traceback.format_exc()\n",
    "                self._log(f\"❌ Connection error: {str(e)}\", \"ERROR\")\n",
    "                \n",
    "                # Check if server crashed\n",
    "                health, _ = self.check_server_health()\n",
    "                if health == ServerHealth.CRASHED:\n",
    "                    last_error_category = ErrorCategory.SERVER_CRASH\n",
    "                    return {\"error\": \"Server crashed or unreachable\"}, elapsed, False, ErrorCategory.SERVER_CRASH, stack_trace\n",
    "            \n",
    "            except requests.exceptions.Timeout as e:\n",
    "                elapsed = time.time() - start_time\n",
    "                last_error = e\n",
    "                last_error_category = ErrorCategory.TIMEOUT\n",
    "                stack_trace = traceback.format_exc()\n",
    "                self._log(f\"❌ Timeout after {elapsed:.3f}s\", \"ERROR\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                elapsed = time.time() - start_time\n",
    "                last_error = e\n",
    "                last_error_category = self._categorize_error(e)\n",
    "                stack_trace = traceback.format_exc()\n",
    "                self._log(f\"❌ Exception: {str(e)}\", \"ERROR\")\n",
    "            \n",
    "            retry_count += 1\n",
    "            \n",
    "            # Exponential backoff before retry\n",
    "            if retry_count < max_retries and retry:\n",
    "                backoff = min(2 ** retry_count, 10)  # Max 10 seconds\n",
    "                self._log(f\"⏳ Retrying in {backoff}s...\")\n",
    "                time.sleep(backoff)\n",
    "        \n",
    "        # All retries failed\n",
    "        return {\n",
    "            \"error\": str(last_error) if last_error else \"Unknown error\",\n",
    "            \"retry_count\": retry_count\n",
    "        }, elapsed, False, last_error_category or ErrorCategory.UNKNOWN, stack_trace\n",
    "\n",
    "def record_test_result(test_name: str, success: bool, elapsed: float, details: Dict = None, \n",
    "                      error_category: Optional[str] = None, stack_trace: Optional[str] = None,\n",
    "                      skipped: bool = False, skip_reason: Optional[str] = None, retry_count: int = 0):\n",
    "    \"\"\"Record test result for final report with enhanced metadata\"\"\"\n",
    "    \n",
    "    # Get current server health\n",
    "    server_health = GLOBAL_STATE[\"server_health_history\"][-1][\"health\"] if GLOBAL_STATE[\"server_health_history\"] else ServerHealth.UNKNOWN\n",
    "    \n",
    "    result = {\n",
    "        \"test_name\": test_name,\n",
    "        \"success\": success,\n",
    "        \"elapsed_seconds\": elapsed,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"details\": details or {},\n",
    "        \"error_category\": error_category,\n",
    "        \"stack_trace\": stack_trace,\n",
    "        \"skipped\": skipped,\n",
    "        \"skip_reason\": skip_reason,\n",
    "        \"retry_count\": retry_count,\n",
    "        \"server_health\": server_health,\n",
    "    }\n",
    "    GLOBAL_STATE[\"test_results\"].append(result)\n",
    "    \n",
    "    # Track timing by endpoint (only for successful tests)\n",
    "    if success and not skipped:\n",
    "        if test_name not in GLOBAL_STATE[\"timing_data\"]:\n",
    "            GLOBAL_STATE[\"timing_data\"][test_name] = []\n",
    "        GLOBAL_STATE[\"timing_data\"][test_name].append(elapsed)\n",
    "    \n",
    "    # Track failed dependencies\n",
    "    if not success and not skipped:\n",
    "        GLOBAL_STATE[\"failed_dependencies\"].add(test_name)\n",
    "\n",
    "def check_dependencies(*required_tests) -> Tuple[bool, Optional[str]]:\n",
    "    \"\"\"Check if required tests have passed. Returns (dependencies_met, skip_reason)\"\"\"\n",
    "    for test in required_tests:\n",
    "        if test in GLOBAL_STATE[\"failed_dependencies\"]:\n",
    "            return False, f\"Dependency failed: {test}\"\n",
    "    return True, None\n",
    "\n",
    "def run_test_with_error_handling(test_name: str, test_func, dependencies: List[str] = None):\n",
    "    \"\"\"Universal test wrapper with error handling and dependency checking\"\"\"\n",
    "    dependencies = dependencies or []\n",
    "    \n",
    "    # Check dependencies\n",
    "    deps_met, skip_reason = check_dependencies(*dependencies)\n",
    "    if not deps_met:\n",
    "        print(f\"\\n⏭️  Test skipped: {skip_reason}\")\n",
    "        record_test_result(test_name, False, 0, skipped=True, skip_reason=skip_reason)\n",
    "        return None\n",
    "    \n",
    "    # Check server health before test\n",
    "    print(f\"\\n🏥 Checking server health...\")\n",
    "    health, health_details = api.check_server_health()\n",
    "    print(f\"   Server status: {health} - {health_details.get('status', 'unknown')}\")\n",
    "    \n",
    "    if health == ServerHealth.CRASHED:\n",
    "        print(f\"\\n💀 Server crashed! Cannot run test.\")\n",
    "        record_test_result(test_name, False, 0, \n",
    "                          details={\"server_crashed\": True}, \n",
    "                          error_category=ErrorCategory.SERVER_CRASH,\n",
    "                          skipped=True,\n",
    "                          skip_reason=\"Server crashed\")\n",
    "        return None\n",
    "    \n",
    "    # Run test\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        result = test_func()\n",
    "        elapsed = time.time() - start_time\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        elapsed = time.time() - start_time\n",
    "        error_msg = str(e)\n",
    "        stack = traceback.format_exc()\n",
    "        \n",
    "        print(f\"\\n💥 UNHANDLED EXCEPTION in test '{test_name}':\")\n",
    "        print(f\"   Error: {error_msg}\")\n",
    "        if VERBOSE_LOGGING:\n",
    "            print(f\"   Stack trace:\\n{stack}\")\n",
    "        \n",
    "        record_test_result(test_name, False, elapsed,\n",
    "                          details={\"unhandled_exception\": error_msg},\n",
    "                          error_category=ErrorCategory.UNKNOWN,\n",
    "                          stack_trace=stack)\n",
    "        return None\n",
    "\n",
    "def print_section(title: str):\n",
    "    \"\"\"Print formatted section header\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {title}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Initialize API client\n",
    "api = APIClient(BASE_URL, API_TIMEOUT, RETRY_ATTEMPTS)\n",
    "\n",
    "print(\"✅ Helper functions defined\")\n",
    "print(\"✅ API client initialized with retry logic\")\n",
    "print(f\"   Max retries: {RETRY_ATTEMPTS}\")\n",
    "print(f\"   Timeout: {API_TIMEOUT}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test: Create Account\n",
    "\n",
    "Create a new user account and obtain an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 1: Create Account\")\n",
    "\n",
    "try:\n",
    "    # Check server health\n",
    "    print(\"🏥 Checking server health...\")\n",
    "    health, health_details = api.check_server_health()\n",
    "    print(f\"   Server status: {health} - {health_details.get('status', 'unknown')}\")\n",
    "    \n",
    "    if health == ServerHealth.CRASHED:\n",
    "        print(\"\\n💀 Server is not responding! Cannot create account.\")\n",
    "        record_test_result(\"Create Account\", False, 0, \n",
    "                          details={\"server_crashed\": True}, \n",
    "                          error_category=ErrorCategory.SERVER_CRASH,\n",
    "                          skipped=True,\n",
    "                          skip_reason=\"Server crashed\")\n",
    "    else:\n",
    "        request_data = {\n",
    "            \"metadata\": \"Test account created from Jupyter notebook\"\n",
    "        }\n",
    "        \n",
    "        response, elapsed, success, error_category, stack_trace = api.request(\"POST\", \"/account/create\", data=request_data)\n",
    "        \n",
    "        if success:\n",
    "            GLOBAL_STATE[\"api_key\"] = response.get(\"api_key\")\n",
    "            GLOBAL_STATE[\"account_id\"] = response.get(\"account_id\")\n",
    "            \n",
    "            print(f\"\\n✅ Account created successfully!\")\n",
    "            print(f\"   Account ID: {GLOBAL_STATE['account_id']}\")\n",
    "            print(f\"   API Key: {GLOBAL_STATE['api_key'][:20]}...\" if GLOBAL_STATE['api_key'] else \"   API Key: None\")\n",
    "            if response.get('warning'):\n",
    "                print(f\"\\n⚠️  {response.get('warning')}\")\n",
    "        else:\n",
    "            print(f\"\\n❌ Failed to create account: {response.get('error', 'Unknown error')}\")\n",
    "            print(f\"   Error category: {error_category}\")\n",
    "        \n",
    "        record_test_result(\"Create Account\", success, elapsed, response, \n",
    "                          error_category=error_category, stack_trace=stack_trace)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n💥 UNHANDLED EXCEPTION: {str(e)}\")\n",
    "    stack = traceback.format_exc()\n",
    "    if VERBOSE_LOGGING:\n",
    "        print(f\"   Stack trace:\\n{stack}\")\n",
    "    record_test_result(\"Create Account\", False, 0,\n",
    "                      details={\"unhandled_exception\": str(e)},\n",
    "                      error_category=ErrorCategory.UNKNOWN,\n",
    "                      stack_trace=stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test: Login\n",
    "\n",
    "Login with API key to obtain a session token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 2: Login\")\n",
    "\n",
    "try:\n",
    "    # Check dependencies\n",
    "    deps_met, skip_reason = check_dependencies(\"Create Account\")\n",
    "    if not deps_met:\n",
    "        print(f\"\\n⏭️  Test skipped: {skip_reason}\")\n",
    "        record_test_result(\"Login\", False, 0, skipped=True, skip_reason=skip_reason)\n",
    "    elif not GLOBAL_STATE[\"api_key\"]:\n",
    "        print(\"❌ No API key available. Create Account test did not provide an API key.\")\n",
    "        record_test_result(\"Login\", False, 0, skipped=True, skip_reason=\"No API key available\")\n",
    "    else:\n",
    "        # Check server health\n",
    "        print(\"🏥 Checking server health...\")\n",
    "        health, health_details = api.check_server_health()\n",
    "        print(f\"   Server status: {health} - {health_details.get('status', 'unknown')}\")\n",
    "        \n",
    "        if health == ServerHealth.CRASHED:\n",
    "            print(\"\\n💀 Server is not responding! Cannot login.\")\n",
    "            record_test_result(\"Login\", False, 0, \n",
    "                              details={\"server_crashed\": True}, \n",
    "                              error_category=ErrorCategory.SERVER_CRASH,\n",
    "                              skipped=True,\n",
    "                              skip_reason=\"Server crashed\")\n",
    "        else:\n",
    "            request_data = {\n",
    "                \"api_key\": GLOBAL_STATE[\"api_key\"]\n",
    "            }\n",
    "            \n",
    "            response, elapsed, success, error_category, stack_trace = api.request(\"POST\", \"/account/login\", data=request_data)\n",
    "            \n",
    "            if success:\n",
    "                GLOBAL_STATE[\"session_token\"] = response.get(\"session_token\")\n",
    "                \n",
    "                print(f\"\\n✅ Login successful!\")\n",
    "                print(f\"   Session Token: {GLOBAL_STATE['session_token'][:30]}...\" if GLOBAL_STATE['session_token'] else \"   Session Token: None\")\n",
    "                print(f\"   Expires in: {response.get('expires_in')} seconds\")\n",
    "            else:\n",
    "                print(f\"\\n❌ Login failed: {response.get('error', 'Unknown error')}\")\n",
    "                print(f\"   Error category: {error_category}\")\n",
    "            \n",
    "            record_test_result(\"Login\", success, elapsed, response,\n",
    "                              error_category=error_category, stack_trace=stack_trace)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n💥 UNHANDLED EXCEPTION: {str(e)}\")\n",
    "    stack = traceback.format_exc()\n",
    "    if VERBOSE_LOGGING:\n",
    "        print(f\"   Stack trace:\\n{stack}\")\n",
    "    record_test_result(\"Login\", False, 0,\n",
    "                      details={\"unhandled_exception\": str(e)},\n",
    "                      error_category=ErrorCategory.UNKNOWN,\n",
    "                      stack_trace=stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test: Submit Data (Single)\n",
    "\n",
    "Submit a single encrypted collection to the blockchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 3: Submit Data (Single)\")\n",
    "\n",
    "try:\n",
    "    # Check dependencies\n",
    "    deps_met, skip_reason = check_dependencies(\"Create Account\")\n",
    "    if not deps_met:\n",
    "        print(f\"\\n⏭️  Test skipped: {skip_reason}\")\n",
    "        record_test_result(\"Submit Data (Single)\", False, 0, skipped=True, skip_reason=skip_reason)\n",
    "    elif not GLOBAL_STATE[\"api_key\"]:\n",
    "        print(\"❌ No API key available. Create Account test did not provide an API key.\")\n",
    "        record_test_result(\"Submit Data (Single)\", False, 0, skipped=True, skip_reason=\"No API key available\")\n",
    "    else:\n",
    "        # Check server health\n",
    "        print(\"🏥 Checking server health...\")\n",
    "        health, health_details = api.check_server_health()\n",
    "        print(f\"   Server status: {health} - {health_details.get('status', 'unknown')}\")\n",
    "        \n",
    "        if health == ServerHealth.CRASHED:\n",
    "            print(\"\\n💀 Server is not responding! Cannot submit data.\")\n",
    "            record_test_result(\"Submit Data (Single)\", False, 0, \n",
    "                              details={\"server_crashed\": True}, \n",
    "                              error_category=ErrorCategory.SERVER_CRASH,\n",
    "                              skipped=True,\n",
    "                              skip_reason=\"Server crashed\")\n",
    "        else:\n",
    "            request_data = {\n",
    "                \"label\": \"Test Collection\",\n",
    "                \"data\": json.dumps({\"message\": \"Hello from Jupyter!\", \"timestamp\": time.time()})\n",
    "            }\n",
    "            \n",
    "            headers = {\"Authorization\": f\"Bearer {GLOBAL_STATE['api_key']}\"}\n",
    "            \n",
    "            response, elapsed, success, error_category, stack_trace = api.request(\"POST\", \"/data/submit\", data=request_data, headers=headers)\n",
    "            \n",
    "            if success:\n",
    "                collection_id = response.get(\"collection_id\")\n",
    "                if collection_id:\n",
    "                    GLOBAL_STATE[\"collection_ids\"].append(collection_id)\n",
    "                \n",
    "                print(f\"\\n✅ Data submitted successfully!\")\n",
    "                print(f\"   Collection ID: {collection_id}\")\n",
    "                print(f\"   Block Number: {response.get('block_number')}\")\n",
    "                print(f\"   Message: {response.get('message')}\")\n",
    "            else:\n",
    "                print(f\"\\n❌ Data submission failed: {response.get('error', 'Unknown error')}\")\n",
    "                print(f\"   Error category: {error_category}\")\n",
    "            \n",
    "            record_test_result(\"Submit Data (Single)\", success, elapsed, response,\n",
    "                              error_category=error_category, stack_trace=stack_trace)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n💥 UNHANDLED EXCEPTION: {str(e)}\")\n",
    "    stack = traceback.format_exc()\n",
    "    if VERBOSE_LOGGING:\n",
    "        print(f\"   Stack trace:\\n{stack}\")\n",
    "    record_test_result(\"Submit Data (Single)\", False, 0,\n",
    "                      details={\"unhandled_exception\": str(e)},\n",
    "                      error_category=ErrorCategory.UNKNOWN,\n",
    "                      stack_trace=stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test: Bulk Data Submission\n",
    "\n",
    "Submit multiple collections to test throughput and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(f\"Test 4: Bulk Data Submission ({BULK_SUBMISSION_COUNT} blocks)\")\n",
    "\n",
    "try:\n",
    "    # Check dependencies\n",
    "    deps_met, skip_reason = check_dependencies(\"Create Account\")\n",
    "    if not deps_met:\n",
    "        print(f\"\\n⏭️  Test skipped: {skip_reason}\")\n",
    "        record_test_result(\"Bulk Data Submission\", False, 0, skipped=True, skip_reason=skip_reason)\n",
    "    elif not GLOBAL_STATE[\"api_key\"]:\n",
    "        print(\"❌ No API key available. Create Account test did not provide an API key.\")\n",
    "        record_test_result(\"Bulk Data Submission\", False, 0, skipped=True, skip_reason=\"No API key available\")\n",
    "    else:\n",
    "        # Check server health\n",
    "        print(\"🏥 Checking server health...\")\n",
    "        health, health_details = api.check_server_health()\n",
    "        print(f\"   Server status: {health} - {health_details.get('status', 'unknown')}\")\n",
    "        \n",
    "        if health == ServerHealth.CRASHED:\n",
    "            print(\"\\n💀 Server is not responding! Cannot run bulk submission.\")\n",
    "            record_test_result(\"Bulk Data Submission\", False, 0, \n",
    "                              details={\"server_crashed\": True}, \n",
    "                              error_category=ErrorCategory.SERVER_CRASH,\n",
    "                              skipped=True,\n",
    "                              skip_reason=\"Server crashed\")\n",
    "        else:\n",
    "            headers = {\"Authorization\": f\"Bearer {GLOBAL_STATE['api_key']}\"}\n",
    "            \n",
    "            start_time = time.time()\n",
    "            successful_submissions = 0\n",
    "            failed_submissions = 0\n",
    "            submission_times = []\n",
    "            error_categories_count = {}\n",
    "            server_crashed = False\n",
    "            \n",
    "            print(f\"Submitting {BULK_SUBMISSION_COUNT} collections...\\n\")\n",
    "            \n",
    "            for i in range(BULK_SUBMISSION_COUNT):\n",
    "                # Check server health periodically during bulk test\n",
    "                if i > 0 and i % 50 == 0:\n",
    "                    health, _ = api.check_server_health()\n",
    "                    if health == ServerHealth.CRASHED:\n",
    "                        print(f\"\\n💀 Server crashed during bulk submission at iteration {i}!\")\n",
    "                        server_crashed = True\n",
    "                        break\n",
    "                \n",
    "                request_data = {\n",
    "                    \"label\": f\"Bulk Test #{i+1}\",\n",
    "                    \"data\": json.dumps({\n",
    "                        \"iteration\": i+1,\n",
    "                        \"timestamp\": time.time(),\n",
    "                        \"test_type\": \"bulk_submission\"\n",
    "                    })\n",
    "                }\n",
    "                \n",
    "                try:\n",
    "                    response, elapsed, success, error_category, stack_trace = api.request(\"POST\", \"/data/submit\", data=request_data, headers=headers, retry=False)\n",
    "                    submission_times.append(elapsed)\n",
    "                    \n",
    "                    if success:\n",
    "                        successful_submissions += 1\n",
    "                        if response.get(\"collection_id\"):\n",
    "                            GLOBAL_STATE[\"collection_ids\"].append(response.get(\"collection_id\"))\n",
    "                    else:\n",
    "                        failed_submissions += 1\n",
    "                        if error_category:\n",
    "                            error_categories_count[error_category] = error_categories_count.get(error_category, 0) + 1\n",
    "                        \n",
    "                        # Stop if server crashed\n",
    "                        if error_category == ErrorCategory.SERVER_CRASH:\n",
    "                            print(f\"\\n💀 Server crashed at iteration {i+1}!\")\n",
    "                            server_crashed = True\n",
    "                            break\n",
    "                    \n",
    "                    # Progress indicator\n",
    "                    if (i + 1) % 10 == 0 or i == BULK_SUBMISSION_COUNT - 1:\n",
    "                        progress = (i + 1) / BULK_SUBMISSION_COUNT * 100\n",
    "                        print(f\"Progress: {i+1}/{BULK_SUBMISSION_COUNT} ({progress:.1f}%) - \"\n",
    "                              f\"Success: {successful_submissions}, Failed: {failed_submissions}\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    failed_submissions += 1\n",
    "                    print(f\"\\n⚠️  Exception at iteration {i+1}: {str(e)}\")\n",
    "            \n",
    "            total_elapsed = time.time() - start_time\n",
    "            avg_time = sum(submission_times) / len(submission_times) if submission_times else 0\n",
    "            throughput = successful_submissions / total_elapsed if total_elapsed > 0 else 0\n",
    "            \n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"📊 Bulk Submission Summary:\")\n",
    "            print(f\"   Total attempted: {successful_submissions + failed_submissions}\")\n",
    "            print(f\"   Successful: {successful_submissions}\")\n",
    "            print(f\"   Failed: {failed_submissions}\")\n",
    "            print(f\"   Success rate: {successful_submissions/(successful_submissions + failed_submissions)*100:.1f}%\" if (successful_submissions + failed_submissions) > 0 else \"   Success rate: N/A\")\n",
    "            print(f\"   Total time: {total_elapsed:.2f}s\")\n",
    "            print(f\"   Average time per submission: {avg_time:.3f}s\")\n",
    "            print(f\"   Throughput: {throughput:.2f} submissions/second\")\n",
    "            if server_crashed:\n",
    "                print(f\"   ⚠️  SERVER CRASHED during test!\")\n",
    "            if error_categories_count:\n",
    "                print(f\"   Error categories:\")\n",
    "                for cat, count in error_categories_count.items():\n",
    "                    print(f\"      {cat}: {count}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            test_success = successful_submissions == BULK_SUBMISSION_COUNT and not server_crashed\n",
    "            \n",
    "            record_test_result(\"Bulk Data Submission\", test_success, \n",
    "                              total_elapsed, {\n",
    "                                  \"total_attempted\": successful_submissions + failed_submissions,\n",
    "                                  \"target\": BULK_SUBMISSION_COUNT,\n",
    "                                  \"successful\": successful_submissions,\n",
    "                                  \"failed\": failed_submissions,\n",
    "                                  \"avg_time\": avg_time,\n",
    "                                  \"throughput\": throughput,\n",
    "                                  \"server_crashed\": server_crashed,\n",
    "                                  \"error_categories\": error_categories_count\n",
    "                              },\n",
    "                              error_category=ErrorCategory.SERVER_CRASH if server_crashed else None)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n💥 UNHANDLED EXCEPTION: {str(e)}\")\n",
    "    stack = traceback.format_exc()\n",
    "    if VERBOSE_LOGGING:\n",
    "        print(f\"   Stack trace:\\n{stack}\")\n",
    "    record_test_result(\"Bulk Data Submission\", False, 0,\n",
    "                      details={\"unhandled_exception\": str(e)},\n",
    "                      error_category=ErrorCategory.UNKNOWN,\n",
    "                      stack_trace=stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test: List Collections\n",
    "\n",
    "Retrieve all collections for the authenticated user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 5: List Collections\")\n",
    "\n",
    "try:\n",
    "    # Check dependencies\n",
    "    deps_met, skip_reason = check_dependencies(\"Create Account\")\n",
    "    if not deps_met:\n",
    "        print(f\"\\n⏭️  Test skipped: {skip_reason}\")\n",
    "        record_test_result(\"List Collections\", False, 0, skipped=True, skip_reason=skip_reason)\n",
    "    elif not GLOBAL_STATE[\"api_key\"]:\n",
    "        print(\"❌ No API key available.\")\n",
    "        record_test_result(\"List Collections\", False, 0, skipped=True, skip_reason=\"No API key available\")\n",
    "    else:\n",
    "        # Check server health\n",
    "        print(\"🏥 Checking server health...\")\n",
    "        health, health_details = api.check_server_health()\n",
    "        print(f\"   Server status: {health} - {health_details.get('status', 'unknown')}\")\n",
    "        \n",
    "        if health == ServerHealth.CRASHED:\n",
    "            print(\"\\n💀 Server is not responding!\")\n",
    "            record_test_result(\"List Collections\", False, 0, \n",
    "                              details={\"server_crashed\": True}, \n",
    "                              error_category=ErrorCategory.SERVER_CRASH,\n",
    "                              skipped=True,\n",
    "                              skip_reason=\"Server crashed\")\n",
    "        else:\n",
    "            headers = {\"Authorization\": f\"Bearer {GLOBAL_STATE['api_key']}\"}\n",
    "            \n",
    "            response, elapsed, success, error_category, stack_trace = api.request(\"GET\", \"/data/list\", headers=headers)\n",
    "            \n",
    "            if success:\n",
    "                collections = response.get(\"collections\", [])\n",
    "                \n",
    "                print(f\"\\n✅ Retrieved {len(collections)} collections\")\n",
    "                \n",
    "                if collections:\n",
    "                    try:\n",
    "                        # Display as DataFrame\n",
    "                        df = pd.DataFrame(collections)\n",
    "                        display(df.head(10))\n",
    "                        \n",
    "                        if len(collections) > 10:\n",
    "                            print(f\"\\n... and {len(collections) - 10} more\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"   ⚠️  Could not display as DataFrame: {str(e)}\")\n",
    "                        print(f\"   Raw data: {collections[:3]}\")  # Show first 3\n",
    "            else:\n",
    "                print(f\"\\n❌ Failed to list collections: {response.get('error', 'Unknown error')}\")\n",
    "                print(f\"   Error category: {error_category}\")\n",
    "            \n",
    "            record_test_result(\"List Collections\", success, elapsed, \n",
    "                              {\"count\": len(collections) if success else 0},\n",
    "                              error_category=error_category, stack_trace=stack_trace)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n💥 UNHANDLED EXCEPTION: {str(e)}\")\n",
    "    stack = traceback.format_exc()\n",
    "    if VERBOSE_LOGGING:\n",
    "        print(f\"   Stack trace:\\n{stack}\")\n",
    "    record_test_result(\"List Collections\", False, 0,\n",
    "                      details={\"unhandled_exception\": str(e)},\n",
    "                      error_category=ErrorCategory.UNKNOWN,\n",
    "                      stack_trace=stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test: Decrypt Collection\n",
    "\n",
    "Decrypt a specific collection to verify data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 6: Decrypt Collection\")\n",
    "\n",
    "try:\n",
    "    # Check dependencies\n",
    "    deps_met, skip_reason = check_dependencies(\"Create Account\", \"Submit Data (Single)\")\n",
    "    if not deps_met:\n",
    "        print(f\"\\n⏭️  Test skipped: {skip_reason}\")\n",
    "        record_test_result(\"Decrypt Collection\", False, 0, skipped=True, skip_reason=skip_reason)\n",
    "    elif not GLOBAL_STATE[\"api_key\"]:\n",
    "        print(\"❌ No API key available.\")\n",
    "        record_test_result(\"Decrypt Collection\", False, 0, skipped=True, skip_reason=\"No API key available\")\n",
    "    elif not GLOBAL_STATE[\"collection_ids\"]:\n",
    "        print(\"❌ No collections available. Submit Data tests did not create any collections.\")\n",
    "        record_test_result(\"Decrypt Collection\", False, 0, skipped=True, skip_reason=\"No collections available\")\n",
    "    else:\n",
    "        # Check server health\n",
    "        print(\"🏥 Checking server health...\")\n",
    "        health, health_details = api.check_server_health()\n",
    "        print(f\"   Server status: {health} - {health_details.get('status', 'unknown')}\")\n",
    "        \n",
    "        if health == ServerHealth.CRASHED:\n",
    "            print(\"\\n💀 Server is not responding!\")\n",
    "            record_test_result(\"Decrypt Collection\", False, 0, \n",
    "                              details={\"server_crashed\": True}, \n",
    "                              error_category=ErrorCategory.SERVER_CRASH,\n",
    "                              skipped=True,\n",
    "                              skip_reason=\"Server crashed\")\n",
    "        else:\n",
    "            # Decrypt the first collection\n",
    "            collection_id = GLOBAL_STATE[\"collection_ids\"][0]\n",
    "            headers = {\"Authorization\": f\"Bearer {GLOBAL_STATE['api_key']}\"}\n",
    "            \n",
    "            response, elapsed, success, error_category, stack_trace = api.request(\"POST\", f\"/data/decrypt/{collection_id}\", headers=headers)\n",
    "            \n",
    "            if success:\n",
    "                print(f\"\\n✅ Collection decrypted successfully!\")\n",
    "                print(f\"   Collection ID: {response.get('collection_id')}\")\n",
    "                print(f\"   Label: {response.get('label')}\")\n",
    "                print(f\"   Created at: {response.get('created_at')}\")\n",
    "                print(f\"   Data: {response.get('data')}\")\n",
    "            else:\n",
    "                print(f\"\\n❌ Decryption failed: {response.get('error', 'Unknown error')}\")\n",
    "                print(f\"   Error category: {error_category}\")\n",
    "            \n",
    "            record_test_result(\"Decrypt Collection\", success, elapsed, response,\n",
    "                              error_category=error_category, stack_trace=stack_trace)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n💥 UNHANDLED EXCEPTION: {str(e)}\")\n",
    "    stack = traceback.format_exc()\n",
    "    if VERBOSE_LOGGING:\n",
    "        print(f\"   Stack trace:\\n{stack}\")\n",
    "    record_test_result(\"Decrypt Collection\", False, 0,\n",
    "                      details={\"unhandled_exception\": str(e)},\n",
    "                      error_category=ErrorCategory.UNKNOWN,\n",
    "                      stack_trace=stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test: View Blockchain\n",
    "\n",
    "Retrieve the entire blockchain state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 7: View Blockchain\")\n",
    "\n",
    "try:\n",
    "    # Check server health\n",
    "    print(\"🏥 Checking server health...\")\n",
    "    health, health_details = api.check_server_health()\n",
    "    print(f\"   Server status: {health} - {health_details.get('status', 'unknown')}\")\n",
    "    \n",
    "    if health == ServerHealth.CRASHED:\n",
    "        print(\"\\n💀 Server is not responding!\")\n",
    "        record_test_result(\"View Blockchain\", False, 0, \n",
    "                          details={\"server_crashed\": True}, \n",
    "                          error_category=ErrorCategory.SERVER_CRASH,\n",
    "                          skipped=True,\n",
    "                          skip_reason=\"Server crashed\")\n",
    "    else:\n",
    "        response, elapsed, success, error_category, stack_trace = api.request(\"GET\", \"/chain\")\n",
    "        \n",
    "        if success:\n",
    "            chain_length = len(response.get(\"chain\", []))\n",
    "            node_id = response.get(\"node_id\", \"unknown\")\n",
    "            \n",
    "            print(f\"\\n✅ Blockchain retrieved successfully!\")\n",
    "            print(f\"   Node ID: {node_id}\")\n",
    "            print(f\"   Chain length: {chain_length} blocks\")\n",
    "            \n",
    "            if chain_length > 0:\n",
    "                try:\n",
    "                    latest_block = response[\"chain\"][-1]\n",
    "                    print(f\"   Latest block index: {latest_block.get('index')}\")\n",
    "                    print(f\"   Latest block timestamp: {latest_block.get('timestamp')}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   ⚠️  Could not parse latest block: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"\\n❌ Failed to retrieve blockchain: {response.get('error', 'Unknown error')}\")\n",
    "            print(f\"   Error category: {error_category}\")\n",
    "            chain_length = 0\n",
    "        \n",
    "        record_test_result(\"View Blockchain\", success, elapsed, \n",
    "                          {\"chain_length\": chain_length},\n",
    "                          error_category=error_category, stack_trace=stack_trace)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n💥 UNHANDLED EXCEPTION: {str(e)}\")\n",
    "    stack = traceback.format_exc()\n",
    "    if VERBOSE_LOGGING:\n",
    "        print(f\"   Stack trace:\\n{stack}\")\n",
    "    record_test_result(\"View Blockchain\", False, 0,\n",
    "                      details={\"unhandled_exception\": str(e)},\n",
    "                      error_category=ErrorCategory.UNKNOWN,\n",
    "                      stack_trace=stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test: Chain Statistics\n",
    "\n",
    "Get analytics and statistics about the blockchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 8: Chain Statistics\")\n",
    "\n",
    "try:\n",
    "    # Check server health\n",
    "    print(\"🏥 Checking server health...\")\n",
    "    health, health_details = api.check_server_health()\n",
    "    print(f\"   Server status: {health} - {health_details.get('status', 'unknown')}\")\n",
    "    \n",
    "    if health == ServerHealth.CRASHED:\n",
    "        print(\"\\n💀 Server is not responding!\")\n",
    "        record_test_result(\"Chain Statistics\", False, 0, \n",
    "                          details={\"server_crashed\": True}, \n",
    "                          error_category=ErrorCategory.SERVER_CRASH,\n",
    "                          skipped=True,\n",
    "                          skip_reason=\"Server crashed\")\n",
    "    else:\n",
    "        response, elapsed, success, error_category, stack_trace = api.request(\"GET\", \"/stats\")\n",
    "        \n",
    "        if success:\n",
    "            print(f\"\\n✅ Statistics retrieved successfully!\")\n",
    "            print(f\"   Total blocks: {response.get('total_blocks')}\")\n",
    "            print(f\"   Total collections: {response.get('total_collections')}\")\n",
    "            print(f\"   Total accounts: {response.get('total_accounts')}\")\n",
    "            print(f\"   Avg block time: {response.get('avg_block_time_seconds', 0):.3f}s\")\n",
    "            \n",
    "            validator_dist = response.get('validator_distribution', {})\n",
    "            if validator_dist:\n",
    "                print(f\"\\n   Validator distribution:\")\n",
    "                for validator, count in validator_dist.items():\n",
    "                    print(f\"      {validator}: {count} blocks\")\n",
    "        else:\n",
    "            print(f\"\\n❌ Failed to retrieve statistics: {response.get('error', 'Unknown error')}\")\n",
    "            print(f\"   Error category: {error_category}\")\n",
    "        \n",
    "        record_test_result(\"Chain Statistics\", success, elapsed, response,\n",
    "                          error_category=error_category, stack_trace=stack_trace)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n💥 UNHANDLED EXCEPTION: {str(e)}\")\n",
    "    stack = traceback.format_exc()\n",
    "    if VERBOSE_LOGGING:\n",
    "        print(f\"   Stack trace:\\n{stack}\")\n",
    "    record_test_result(\"Chain Statistics\", False, 0,\n",
    "                      details={\"unhandled_exception\": str(e)},\n",
    "                      error_category=ErrorCategory.UNKNOWN,\n",
    "                      stack_trace=stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Test: Node Metrics\n",
    "\n",
    "Get performance metrics from the current node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 9: Node Metrics\")\n",
    "\n",
    "try:\n",
    "    # Check server health\n",
    "    print(\"🏥 Checking server health...\")\n",
    "    health, health_details = api.check_server_health()\n",
    "    print(f\"   Server status: {health} - {health_details.get('status', 'unknown')}\")\n",
    "    \n",
    "    if health == ServerHealth.CRASHED:\n",
    "        print(\"\\n💀 Server is not responding!\")\n",
    "        record_test_result(\"Node Metrics\", False, 0, \n",
    "                          details={\"server_crashed\": True}, \n",
    "                          error_category=ErrorCategory.SERVER_CRASH,\n",
    "                          skipped=True,\n",
    "                          skip_reason=\"Server crashed\")\n",
    "    else:\n",
    "        response, elapsed, success, error_category, stack_trace = api.request(\"GET\", \"/metrics\")\n",
    "        \n",
    "        if success:\n",
    "            print(f\"\\n✅ Metrics retrieved successfully!\")\n",
    "            print(f\"   Node ID: {response.get('node_id')}\")\n",
    "            print(f\"   Chain length: {response.get('chain_length')}\")\n",
    "            print(f\"   Peer count: {response.get('peer_count')}\")\n",
    "            print(f\"   Latest block index: {response.get('latest_block_index')}\")\n",
    "            print(f\"   Latest block timestamp: {response.get('latest_block_timestamp')}\")\n",
    "            print(f\"   Status: {response.get('status')}\")\n",
    "        else:\n",
    "            print(f\"\\n❌ Failed to retrieve metrics: {response.get('error', 'Unknown error')}\")\n",
    "            print(f\"   Error category: {error_category}\")\n",
    "        \n",
    "        record_test_result(\"Node Metrics\", success, elapsed, response,\n",
    "                          error_category=error_category, stack_trace=stack_trace)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n💥 UNHANDLED EXCEPTION: {str(e)}\")\n",
    "    stack = traceback.format_exc()\n",
    "    if VERBOSE_LOGGING:\n",
    "        print(f\"   Stack trace:\\n{stack}\")\n",
    "    record_test_result(\"Node Metrics\", False, 0,\n",
    "                      details={\"unhandled_exception\": str(e)},\n",
    "                      error_category=ErrorCategory.UNKNOWN,\n",
    "                      stack_trace=stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Test: P2P Peers\n",
    "\n",
    "View connected P2P peers and their reputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 10: P2P Peers\")\n",
    "\n",
    "try:\n",
    "    # Check server health\n",
    "    print(\"🏥 Checking server health...\")\n",
    "    health, health_details = api.check_server_health()\n",
    "    print(f\"   Server status: {health} - {health_details.get('status', 'unknown')}\")\n",
    "    \n",
    "    if health == ServerHealth.CRASHED:\n",
    "        print(\"\\n💀 Server is not responding!\")\n",
    "        record_test_result(\"P2P Peers\", False, 0, \n",
    "                          details={\"server_crashed\": True}, \n",
    "                          error_category=ErrorCategory.SERVER_CRASH,\n",
    "                          skipped=True,\n",
    "                          skip_reason=\"Server crashed\")\n",
    "    else:\n",
    "        response, elapsed, success, error_category, stack_trace = api.request(\"GET\", \"/peers\")\n",
    "        \n",
    "        if success:\n",
    "            peers = response.get('peers', [])\n",
    "            reputation = response.get('reputation', {})\n",
    "            \n",
    "            print(f\"\\n✅ Peer information retrieved successfully!\")\n",
    "            print(f\"   Connected peers: {response.get('count', 0)}\")\n",
    "            \n",
    "            if peers:\n",
    "                print(f\"\\n   Peer list:\")\n",
    "                for peer in peers:\n",
    "                    rep = reputation.get(peer, 0)\n",
    "                    print(f\"      {peer} (reputation: {rep})\")\n",
    "            else:\n",
    "                print(f\"   No peers connected\")\n",
    "        else:\n",
    "            print(f\"\\n❌ Failed to retrieve peers: {response.get('error', 'Unknown error')}\")\n",
    "            print(f\"   Error category: {error_category}\")\n",
    "        \n",
    "        record_test_result(\"P2P Peers\", success, elapsed, response,\n",
    "                          error_category=error_category, stack_trace=stack_trace)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n💥 UNHANDLED EXCEPTION: {str(e)}\")\n",
    "    stack = traceback.format_exc()\n",
    "    if VERBOSE_LOGGING:\n",
    "        print(f\"   Stack trace:\\n{stack}\")\n",
    "    record_test_result(\"P2P Peers\", False, 0,\n",
    "                      details={\"unhandled_exception\": str(e)},\n",
    "                      error_category=ErrorCategory.UNKNOWN,\n",
    "                      stack_trace=stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Test: Health Check\n",
    "\n",
    "Verify node health status (used by load balancer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 11: Health Check\")\n",
    "\n",
    "try:\n",
    "    # No dependency or health check needed since this IS the health check\n",
    "    response, elapsed, success, error_category, stack_trace = api.request(\"GET\", \"/health\")\n",
    "    \n",
    "    if success:\n",
    "        print(f\"\\n✅ Node is healthy!\")\n",
    "        print(f\"   Status: {response.get('status')}\")\n",
    "        print(f\"   Node ID: {response.get('node_id')}\")\n",
    "        print(f\"   Chain length: {response.get('chain_length')}\")\n",
    "        print(f\"   Peer count: {response.get('peer_count')}\")\n",
    "        print(f\"   Latest block: {response.get('latest_block')}\")\n",
    "    else:\n",
    "        print(f\"\\n❌ Health check failed: {response.get('error', 'Unknown error')}\")\n",
    "        print(f\"   Error category: {error_category}\")\n",
    "        print(f\"   This indicates the server is either crashed, degraded, or experiencing issues\")\n",
    "    \n",
    "    record_test_result(\"Health Check\", success, elapsed, response,\n",
    "                      error_category=error_category, stack_trace=stack_trace)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n💥 UNHANDLED EXCEPTION: {str(e)}\")\n",
    "    stack = traceback.format_exc()\n",
    "    if VERBOSE_LOGGING:\n",
    "        print(f\"   Stack trace:\\n{stack}\")\n",
    "    record_test_result(\"Health Check\", False, 0,\n",
    "                      details={\"unhandled_exception\": str(e)},\n",
    "                      error_category=ErrorCategory.UNKNOWN,\n",
    "                      stack_trace=stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Final Report & Visualizations\n",
    "\n",
    "Generate comprehensive report with timing analysis and charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Final Report & Analysis\")\n",
    "\n",
    "try:\n",
    "    # Calculate summary statistics\n",
    "    total_tests = len(GLOBAL_STATE[\"test_results\"])\n",
    "    successful_tests = sum(1 for r in GLOBAL_STATE[\"test_results\"] if r[\"success\"] and not r.get(\"skipped\"))\n",
    "    failed_tests = sum(1 for r in GLOBAL_STATE[\"test_results\"] if not r[\"success\"] and not r.get(\"skipped\"))\n",
    "    skipped_tests = sum(1 for r in GLOBAL_STATE[\"test_results\"] if r.get(\"skipped\"))\n",
    "    success_rate = (successful_tests / (successful_tests + failed_tests) * 100) if (successful_tests + failed_tests) > 0 else 0\n",
    "    \n",
    "    total_time = sum(r[\"elapsed_seconds\"] for r in GLOBAL_STATE[\"test_results\"])\n",
    "    avg_time = total_time / total_tests if total_tests > 0 else 0\n",
    "    \n",
    "    print(f\"\\n📊 Test Execution Summary:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total tests: {total_tests}\")\n",
    "    print(f\"Successful: {successful_tests}\")\n",
    "    print(f\"Failed: {failed_tests}\")\n",
    "    print(f\"Skipped: {skipped_tests}\")\n",
    "    print(f\"Success rate: {success_rate:.1f}% (excluding skipped)\")\n",
    "    print(f\"Total execution time: {total_time:.2f}s\")\n",
    "    print(f\"Average time per test: {avg_time:.3f}s\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Error category analysis\n",
    "    error_categories = {}\n",
    "    for result in GLOBAL_STATE[\"test_results\"]:\n",
    "        if result.get(\"error_category\"):\n",
    "            cat = result[\"error_category\"]\n",
    "            error_categories[cat] = error_categories.get(cat, 0) + 1\n",
    "    \n",
    "    if error_categories:\n",
    "        print(f\"\\n🔍 Error Category Breakdown:\")\n",
    "        print(f\"{'='*60}\")\n",
    "        for category, count in sorted(error_categories.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"   {category}: {count} occurrences\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Server health timeline\n",
    "    if GLOBAL_STATE[\"server_health_history\"]:\n",
    "        print(f\"\\n🏥 Server Health Timeline:\")\n",
    "        print(f\"{'='*60}\")\n",
    "        health_counts = {}\n",
    "        for entry in GLOBAL_STATE[\"server_health_history\"]:\n",
    "            health = entry[\"health\"]\n",
    "            health_counts[health] = health_counts.get(health, 0) + 1\n",
    "        \n",
    "        for health, count in sorted(health_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"   {health}: {count} checks\")\n",
    "        \n",
    "        # Check for crashes\n",
    "        crashes = [e for e in GLOBAL_STATE[\"server_health_history\"] if e[\"health\"] == ServerHealth.CRASHED]\n",
    "        if crashes:\n",
    "            print(f\"\\n   ⚠️  SERVER CRASHES DETECTED: {len(crashes)} times\")\n",
    "            print(f\"   First crash at: {crashes[0]['timestamp']}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Dependency chain analysis\n",
    "    if GLOBAL_STATE[\"failed_dependencies\"]:\n",
    "        print(f\"\\n🔗 Failed Dependencies (blocking downstream tests):\")\n",
    "        print(f\"{'='*60}\")\n",
    "        for dep in GLOBAL_STATE[\"failed_dependencies\"]:\n",
    "            blocked_tests = [r for r in GLOBAL_STATE[\"test_results\"] \n",
    "                           if r.get(\"skip_reason\") and dep in r.get(\"skip_reason\", \"\")]\n",
    "            print(f\"   '{dep}' blocked {len(blocked_tests)} downstream test(s)\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    df_results = pd.DataFrame(GLOBAL_STATE[\"test_results\"])\n",
    "    \n",
    "    print(\"\\n📋 Detailed Results:\")\n",
    "    display_cols = [\"test_name\", \"success\", \"skipped\", \"elapsed_seconds\", \"error_category\", \"server_health\"]\n",
    "    if all(col in df_results.columns for col in display_cols):\n",
    "        display(df_results[display_cols])\n",
    "    else:\n",
    "        display(df_results)\n",
    "    \n",
    "    # Export to CSV if configured\n",
    "    if EXPORT_TO_CSV:\n",
    "        try:\n",
    "            csv_path = f\"{REPORT_OUTPUT_DIR}test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "            df_results.to_csv(csv_path, index=False)\n",
    "            print(f\"\\n✅ Results exported to: {csv_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n⚠️  Failed to export CSV: {str(e)}\")\n",
    "    \n",
    "    # Export to JSON if configured\n",
    "    if EXPORT_TO_JSON:\n",
    "        try:\n",
    "            json_path = f\"{REPORT_OUTPUT_DIR}test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "            with open(json_path, 'w') as f:\n",
    "                json.dump({\n",
    "                    \"test_run_info\": {\n",
    "                        \"timestamp\": datetime.now().isoformat(),\n",
    "                        \"base_url\": BASE_URL,\n",
    "                        \"bulk_submission_count\": BULK_SUBMISSION_COUNT,\n",
    "                        \"api_timeout\": API_TIMEOUT,\n",
    "                        \"retry_attempts\": RETRY_ATTEMPTS,\n",
    "                    },\n",
    "                    \"system_info\": GLOBAL_STATE[\"system_info\"],\n",
    "                    \"summary\": {\n",
    "                        \"total_tests\": total_tests,\n",
    "                        \"successful\": successful_tests,\n",
    "                        \"failed\": failed_tests,\n",
    "                        \"skipped\": skipped_tests,\n",
    "                        \"success_rate\": success_rate,\n",
    "                        \"total_time\": total_time,\n",
    "                        \"avg_time\": avg_time,\n",
    "                        \"error_categories\": error_categories,\n",
    "                    },\n",
    "                    \"server_health_summary\": {\n",
    "                        \"total_checks\": len(GLOBAL_STATE[\"server_health_history\"]),\n",
    "                        \"crash_count\": len([e for e in GLOBAL_STATE[\"server_health_history\"] if e[\"health\"] == ServerHealth.CRASHED]),\n",
    "                        \"timeline\": GLOBAL_STATE[\"server_health_history\"],\n",
    "                    },\n",
    "                    \"results\": GLOBAL_STATE[\"test_results\"],\n",
    "                    \"global_state\": {\n",
    "                        \"account_id\": GLOBAL_STATE[\"account_id\"],\n",
    "                        \"collection_count\": len(GLOBAL_STATE[\"collection_ids\"]),\n",
    "                        \"failed_dependencies\": list(GLOBAL_STATE[\"failed_dependencies\"]),\n",
    "                    }\n",
    "                }, f, indent=2)\n",
    "            print(f\"✅ Results exported to: {json_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n⚠️  Failed to export JSON: {str(e)}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\n💡 Recommendations:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if failed_tests == 0 and skipped_tests == 0:\n",
    "        print(\"   ✅ All tests passed! System is healthy.\")\n",
    "    else:\n",
    "        if ErrorCategory.SERVER_CRASH in error_categories:\n",
    "            print(\"   🚨 Server crashed during testing - check memory limits and logs\")\n",
    "        if ErrorCategory.TIMEOUT in error_categories:\n",
    "            print(\"   ⏱️  Timeouts detected - consider increasing API_TIMEOUT or investigating slow endpoints\")\n",
    "        if ErrorCategory.CONNECTION_ERROR in error_categories:\n",
    "            print(\"   🔌 Connection errors detected - verify network configuration and container health\")\n",
    "        if skipped_tests > 0:\n",
    "            print(f\"   ⏭️  {skipped_tests} tests skipped due to failed dependencies - fix root causes first\")\n",
    "        if failed_tests > successful_tests:\n",
    "            print(\"   🔥 More failures than successes - system may be fundamentally broken\")\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n💥 UNHANDLED EXCEPTION in reporting: {str(e)}\")\n",
    "    stack = traceback.format_exc()\n",
    "    print(f\"   Stack trace:\\n{stack}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate timing charts and failure analysis visualizations\n",
    "try:\n",
    "    if GENERATE_CHARTS and (GLOBAL_STATE[\"timing_data\"] or GLOBAL_STATE[\"test_results\"]):\n",
    "        print(\"\\n📊 Generating performance charts and failure analysis...\\n\")\n",
    "        \n",
    "        # Determine how many charts to create\n",
    "        has_timing_data = bool(GLOBAL_STATE[\"timing_data\"])\n",
    "        has_test_data = bool(GLOBAL_STATE[\"test_results\"])\n",
    "        \n",
    "        num_charts = 0\n",
    "        if has_timing_data:\n",
    "            num_charts += 2  # Average latency + distribution\n",
    "        if has_test_data:\n",
    "            num_charts += 2  # Error category pie chart + server health timeline\n",
    "        \n",
    "        if num_charts == 0:\n",
    "            print(\"⚠️  No data available for charting\")\n",
    "        else:\n",
    "            # Create figure with appropriate number of subplots\n",
    "            if num_charts == 4:\n",
    "                fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "                axes = [ax1, ax2, ax3, ax4]\n",
    "            elif num_charts == 3:\n",
    "                fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "                axes = [ax1, ax2, ax3]\n",
    "            elif num_charts == 2:\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "                axes = [ax1, ax2]\n",
    "            else:\n",
    "                fig, ax1 = plt.subplots(1, 1, figsize=(8, 6))\n",
    "                axes = [ax1]\n",
    "            \n",
    "            chart_idx = 0\n",
    "            \n",
    "            # Chart 1: Average latency per endpoint\n",
    "            if has_timing_data:\n",
    "                endpoints = list(GLOBAL_STATE[\"timing_data\"].keys())\n",
    "                avg_times = [sum(times)/len(times) for times in GLOBAL_STATE[\"timing_data\"].values()]\n",
    "                \n",
    "                axes[chart_idx].barh(endpoints, avg_times, color='steelblue')\n",
    "                axes[chart_idx].set_xlabel('Average Response Time (seconds)')\n",
    "                axes[chart_idx].set_title('Average Latency by Endpoint')\n",
    "                axes[chart_idx].grid(axis='x', alpha=0.3)\n",
    "                chart_idx += 1\n",
    "                \n",
    "                # Chart 2: Response time distribution\n",
    "                all_times = []\n",
    "                all_labels = []\n",
    "                for endpoint, times in GLOBAL_STATE[\"timing_data\"].items():\n",
    "                    all_times.extend(times)\n",
    "                    all_labels.extend([endpoint] * len(times))\n",
    "                \n",
    "                df_times = pd.DataFrame({'Endpoint': all_labels, 'Time': all_times})\n",
    "                \n",
    "                # Box plot for distribution\n",
    "                sns.boxplot(data=df_times, y='Endpoint', x='Time', ax=axes[chart_idx])\n",
    "                axes[chart_idx].set_xlabel('Response Time (seconds)')\n",
    "                axes[chart_idx].set_title('Response Time Distribution')\n",
    "                axes[chart_idx].grid(axis='x', alpha=0.3)\n",
    "                chart_idx += 1\n",
    "            \n",
    "            # Chart 3: Error category pie chart\n",
    "            if has_test_data:\n",
    "                error_categories = {}\n",
    "                for result in GLOBAL_STATE[\"test_results\"]:\n",
    "                    if result.get(\"error_category\"):\n",
    "                        cat = result[\"error_category\"]\n",
    "                        error_categories[cat] = error_categories.get(cat, 0) + 1\n",
    "                \n",
    "                if error_categories and chart_idx < len(axes):\n",
    "                    labels = list(error_categories.keys())\n",
    "                    sizes = list(error_categories.values())\n",
    "                    colors = plt.cm.Set3(range(len(labels)))\n",
    "                    \n",
    "                    axes[chart_idx].pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "                    axes[chart_idx].set_title('Error Category Distribution')\n",
    "                    chart_idx += 1\n",
    "                \n",
    "                # Chart 4: Server health timeline\n",
    "                if GLOBAL_STATE[\"server_health_history\"] and chart_idx < len(axes):\n",
    "                    health_timeline = []\n",
    "                    timestamps = []\n",
    "                    \n",
    "                    for i, entry in enumerate(GLOBAL_STATE[\"server_health_history\"]):\n",
    "                        health = entry[\"health\"]\n",
    "                        # Map health to numeric value for plotting\n",
    "                        health_value = {\n",
    "                            ServerHealth.ALIVE: 3,\n",
    "                            ServerHealth.DEGRADED: 2,\n",
    "                            ServerHealth.CRASHED: 1,\n",
    "                            ServerHealth.UNKNOWN: 0\n",
    "                        }.get(health, 0)\n",
    "                        health_timeline.append(health_value)\n",
    "                        timestamps.append(i)\n",
    "                    \n",
    "                    axes[chart_idx].plot(timestamps, health_timeline, marker='o', linewidth=2, markersize=6)\n",
    "                    axes[chart_idx].set_xlabel('Health Check Number')\n",
    "                    axes[chart_idx].set_ylabel('Server Health')\n",
    "                    axes[chart_idx].set_title('Server Health Timeline')\n",
    "                    axes[chart_idx].set_yticks([0, 1, 2, 3])\n",
    "                    axes[chart_idx].set_yticklabels(['Unknown', 'Crashed', 'Degraded', 'Alive'])\n",
    "                    axes[chart_idx].grid(alpha=0.3)\n",
    "                    \n",
    "                    # Highlight crashes\n",
    "                    crash_indices = [i for i, v in enumerate(health_timeline) if v == 1]\n",
    "                    if crash_indices:\n",
    "                        axes[chart_idx].scatter([timestamps[i] for i in crash_indices],\n",
    "                                               [health_timeline[i] for i in crash_indices],\n",
    "                                               color='red', s=200, alpha=0.5, zorder=5,\n",
    "                                               label='Crashes')\n",
    "                        axes[chart_idx].legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save chart\n",
    "            try:\n",
    "                chart_path = f\"{REPORT_OUTPUT_DIR}performance_chart_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
    "                plt.savefig(chart_path, dpi=150, bbox_inches='tight')\n",
    "                print(f\"✅ Chart saved to: {chart_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Failed to save chart: {str(e)}\")\n",
    "            \n",
    "            plt.show()\n",
    "    \n",
    "    print(\"\\n✅ Report generation complete!\")\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"📁 Artifacts Generated:\")\n",
    "    print(f\"   - Test results DataFrame (displayed above)\")\n",
    "    if EXPORT_TO_CSV:\n",
    "        print(f\"   - CSV export: {REPORT_OUTPUT_DIR}test_results_*.csv\")\n",
    "    if EXPORT_TO_JSON:\n",
    "        print(f\"   - JSON export: {REPORT_OUTPUT_DIR}test_results_*.json\")\n",
    "    if GENERATE_CHARTS:\n",
    "        print(f\"   - Performance charts: {REPORT_OUTPUT_DIR}performance_chart_*.png\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n💥 UNHANDLED EXCEPTION in chart generation: {str(e)}\")\n",
    "    stack = traceback.format_exc()\n",
    "    print(f\"   Stack trace:\\n{stack}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ All tests completed with comprehensive error handling and resilience!\n",
    "\n",
    "**Enhanced Features:**\n",
    "- 🛡️ **Error-Resistant Design**: Every test wrapped in try-except blocks to prevent cascading failures\n",
    "- 🏥 **Server Health Monitoring**: Automatic health checks before each test to detect server crashes\n",
    "- 🔄 **Automatic Retry Logic**: Failed requests retry with exponential backoff (configurable via `RETRY_ATTEMPTS`)\n",
    "- 🔗 **Dependency Tracking**: Tests automatically skip if prerequisites failed, preventing false positives\n",
    "- 📊 **Comprehensive Diagnostics**: Error categorization, server health timeline, dependency chain analysis\n",
    "- 💻 **System Information**: Captures CPU, memory, disk, platform info dynamically\n",
    "- 📈 **Enhanced Reporting**: Failure analysis with actionable recommendations\n",
    "\n",
    "**Error Categories Tracked:**\n",
    "- `connection_error` - Cannot connect to server\n",
    "- `timeout` - Request exceeded timeout limit\n",
    "- `http_error` - HTTP error status (4xx, 5xx)\n",
    "- `server_crash` - Server completely unresponsive\n",
    "- `json_parse_error` - Invalid JSON response\n",
    "- `authentication_error` - Auth failures (401, 403)\n",
    "- `unknown` - Unhandled exception types\n",
    "\n",
    "**Artifacts Generated:**\n",
    "- 📋 Test Results DataFrame (displayed in notebook)\n",
    "- 📄 CSV Export: `{REPORT_OUTPUT_DIR}test_results_*.csv`\n",
    "- 📦 JSON Export: `{REPORT_OUTPUT_DIR}test_results_*.json` (includes system info, server health timeline, full test metadata)\n",
    "- 📊 Performance Charts: `{REPORT_OUTPUT_DIR}performance_chart_*.png` (latency, distribution, error breakdown, health timeline)\n",
    "\n",
    "**Global State Variables:**\n",
    "- `GLOBAL_STATE[\"api_key\"]` - API key for authentication\n",
    "- `GLOBAL_STATE[\"account_id\"]` - Account ID\n",
    "- `GLOBAL_STATE[\"collection_ids\"]` - List of created collection IDs\n",
    "- `GLOBAL_STATE[\"test_results\"]` - Detailed results for all tests\n",
    "- `GLOBAL_STATE[\"system_info\"]` - System/environment information\n",
    "- `GLOBAL_STATE[\"server_health_history\"]` - Timeline of server health checks\n",
    "- `GLOBAL_STATE[\"failed_dependencies\"]` - Set of tests that failed (blocking downstream tests)\n",
    "\n",
    "**Next Steps:**\n",
    "1. Review the detailed results and recommendations above\n",
    "2. Check exported JSON for full test metadata and system info\n",
    "3. Analyze performance charts to identify bottlenecks\n",
    "4. If server crashed, check container logs: `docker logs <container_name>`\n",
    "5. Adjust `BULK_SUBMISSION_COUNT` or `API_TIMEOUT` based on results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
