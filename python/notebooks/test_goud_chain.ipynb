{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goud Chain API Testing Suite\n",
    "\n",
    "Comprehensive test notebook for all Goud Chain API endpoints with timing metrics and reporting.\n",
    "\n",
    "**Features:**\n",
    "- Create API keys and authenticate\n",
    "- Bulk data submission (configurable batch size)\n",
    "- Collection management and decryption\n",
    "- Blockchain explorer and analytics\n",
    "- Performance metrics with visualizations\n",
    "- Final report generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Adjust these settings before running tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ Configuration ============\n",
    "\n",
    "# API Endpoint (Docker internal network or external)\n",
    "BASE_URL = \"http://nginx:8080\"  # Use this when running in Docker\n",
    "# BASE_URL = \"http://localhost:8080\"  # Use this for external testing\n",
    "\n",
    "# Test Parameters\n",
    "BULK_SUBMISSION_COUNT = 100  # Number of blocks to create in bulk test\n",
    "API_TIMEOUT = 30  # Request timeout in seconds\n",
    "RETRY_ATTEMPTS = 3  # Number of retries for failed requests\n",
    "\n",
    "# Debug Settings\n",
    "VERBOSE_LOGGING = True  # Print detailed logs\n",
    "SHOW_REQUEST_BODIES = False  # Print full request/response bodies\n",
    "\n",
    "# Report Settings\n",
    "EXPORT_TO_CSV = True  # Export results to CSV\n",
    "EXPORT_TO_JSON = True  # Export results to JSON\n",
    "GENERATE_CHARTS = True  # Generate timing charts\n",
    "REPORT_OUTPUT_DIR = \"../scratch/\"  # Where to save reports\n",
    "\n",
    "print(\"✅ Configuration loaded\")\n",
    "print(f\"📡 API Endpoint: {BASE_URL}\")\n",
    "print(f\"🔢 Bulk submission count: {BULK_SUBMISSION_COUNT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup & Utilities\n",
    "\n",
    "Import libraries and define helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Global state storage\n",
    "GLOBAL_STATE = {\n",
    "    \"api_key\": None,\n",
    "    \"account_id\": None,\n",
    "    \"session_token\": None,\n",
    "    \"collection_ids\": [],\n",
    "    \"test_results\": [],\n",
    "    \"timing_data\": {},\n",
    "}\n",
    "\n",
    "# Configure plotting style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✅ Libraries imported\")\n",
    "print(\"✅ Global state initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ Helper Functions ============\n",
    "\n",
    "class APIClient:\n",
    "    \"\"\"Wrapper for Goud Chain API calls with timing and error handling\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url: str, timeout: int = 30):\n",
    "        self.base_url = base_url.rstrip('/')\n",
    "        self.timeout = timeout\n",
    "        self.session = requests.Session()\n",
    "    \n",
    "    def _log(self, message: str, level: str = \"INFO\"):\n",
    "        if VERBOSE_LOGGING or level == \"ERROR\":\n",
    "            timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n",
    "            print(f\"[{timestamp}] {level}: {message}\")\n",
    "    \n",
    "    def request(self, method: str, endpoint: str, data: Optional[Dict] = None, \n",
    "                headers: Optional[Dict] = None) -> tuple[Optional[Dict], float, bool]:\n",
    "        \"\"\"Make HTTP request with timing. Returns (response_data, elapsed_time, success)\"\"\"\n",
    "        url = f\"{self.base_url}{endpoint}\"\n",
    "        headers = headers or {}\n",
    "        \n",
    "        if data:\n",
    "            headers[\"Content-Type\"] = \"application/json\"\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            self._log(f\"{method} {endpoint}\")\n",
    "            \n",
    "            if method == \"GET\":\n",
    "                response = self.session.get(url, headers=headers, timeout=self.timeout)\n",
    "            elif method == \"POST\":\n",
    "                response = self.session.post(url, json=data, headers=headers, timeout=self.timeout)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported method: {method}\")\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            if response.status_code >= 200 and response.status_code < 300:\n",
    "                result = response.json() if response.content else {}\n",
    "                self._log(f\"✅ Success ({response.status_code}) in {elapsed:.3f}s\")\n",
    "                return result, elapsed, True\n",
    "            else:\n",
    "                self._log(f\"❌ Failed ({response.status_code}): {response.text}\", \"ERROR\")\n",
    "                return {\"error\": response.text}, elapsed, False\n",
    "        \n",
    "        except Exception as e:\n",
    "            elapsed = time.time() - start_time\n",
    "            self._log(f\"❌ Exception: {str(e)}\", \"ERROR\")\n",
    "            return {\"error\": str(e)}, elapsed, False\n",
    "\n",
    "def record_test_result(test_name: str, success: bool, elapsed: float, details: Dict = None):\n",
    "    \"\"\"Record test result for final report\"\"\"\n",
    "    result = {\n",
    "        \"test_name\": test_name,\n",
    "        \"success\": success,\n",
    "        \"elapsed_seconds\": elapsed,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"details\": details or {}\n",
    "    }\n",
    "    GLOBAL_STATE[\"test_results\"].append(result)\n",
    "    \n",
    "    # Track timing by endpoint\n",
    "    if test_name not in GLOBAL_STATE[\"timing_data\"]:\n",
    "        GLOBAL_STATE[\"timing_data\"][test_name] = []\n",
    "    GLOBAL_STATE[\"timing_data\"][test_name].append(elapsed)\n",
    "\n",
    "def print_section(title: str):\n",
    "    \"\"\"Print formatted section header\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {title}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Initialize API client\n",
    "api = APIClient(BASE_URL, API_TIMEOUT)\n",
    "\n",
    "print(\"✅ Helper functions defined\")\n",
    "print(\"✅ API client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test: Create Account\n",
    "\n",
    "Create a new user account and obtain an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 1: Create Account\")\n",
    "\n",
    "request_data = {\n",
    "    \"metadata\": \"Test account created from Jupyter notebook\"\n",
    "}\n",
    "\n",
    "response, elapsed, success = api.request(\"POST\", \"/account/create\", data=request_data)\n",
    "\n",
    "if success:\n",
    "    GLOBAL_STATE[\"api_key\"] = response.get(\"api_key\")\n",
    "    GLOBAL_STATE[\"account_id\"] = response.get(\"account_id\")\n",
    "    \n",
    "    print(f\"\\n✅ Account created successfully!\")\n",
    "    print(f\"   Account ID: {GLOBAL_STATE['account_id']}\")\n",
    "    print(f\"   API Key: {GLOBAL_STATE['api_key'][:20]}...\")\n",
    "    print(f\"\\n⚠️  {response.get('warning')}\")\n",
    "else:\n",
    "    print(f\"\\n❌ Failed to create account: {response}\")\n",
    "\n",
    "record_test_result(\"Create Account\", success, elapsed, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test: Login\n",
    "\n",
    "Login with API key to obtain a session token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 2: Login\")\n",
    "\n",
    "if not GLOBAL_STATE[\"api_key\"]:\n",
    "    print(\"❌ No API key available. Run the Create Account test first.\")\n",
    "else:\n",
    "    request_data = {\n",
    "        \"api_key\": GLOBAL_STATE[\"api_key\"]\n",
    "    }\n",
    "    \n",
    "    response, elapsed, success = api.request(\"POST\", \"/account/login\", data=request_data)\n",
    "    \n",
    "    if success:\n",
    "        GLOBAL_STATE[\"session_token\"] = response.get(\"session_token\")\n",
    "        \n",
    "        print(f\"\\n✅ Login successful!\")\n",
    "        print(f\"   Session Token: {GLOBAL_STATE['session_token'][:30]}...\")\n",
    "        print(f\"   Expires in: {response.get('expires_in')} seconds\")\n",
    "    else:\n",
    "        print(f\"\\n❌ Login failed: {response}\")\n",
    "    \n",
    "    record_test_result(\"Login\", success, elapsed, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test: Submit Data (Single)\n",
    "\n",
    "Submit a single encrypted collection to the blockchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 3: Submit Data (Single)\")\n",
    "\n",
    "if not GLOBAL_STATE[\"api_key\"]:\n",
    "    print(\"❌ No API key available. Run the Create Account test first.\")\n",
    "else:\n",
    "    request_data = {\n",
    "        \"label\": \"Test Collection\",\n",
    "        \"data\": json.dumps({\"message\": \"Hello from Jupyter!\", \"timestamp\": time.time()})\n",
    "    }\n",
    "    \n",
    "    headers = {\"Authorization\": f\"Bearer {GLOBAL_STATE['api_key']}\"}\n",
    "    \n",
    "    response, elapsed, success = api.request(\"POST\", \"/data/submit\", data=request_data, headers=headers)\n",
    "    \n",
    "    if success:\n",
    "        collection_id = response.get(\"collection_id\")\n",
    "        GLOBAL_STATE[\"collection_ids\"].append(collection_id)\n",
    "        \n",
    "        print(f\"\\n✅ Data submitted successfully!\")\n",
    "        print(f\"   Collection ID: {collection_id}\")\n",
    "        print(f\"   Block Number: {response.get('block_number')}\")\n",
    "        print(f\"   Message: {response.get('message')}\")\n",
    "    else:\n",
    "        print(f\"\\n❌ Data submission failed: {response}\")\n",
    "    \n",
    "    record_test_result(\"Submit Data (Single)\", success, elapsed, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test: Bulk Data Submission\n",
    "\n",
    "Submit multiple collections to test throughput and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(f\"Test 4: Bulk Data Submission ({BULK_SUBMISSION_COUNT} blocks)\")\n",
    "\n",
    "if not GLOBAL_STATE[\"api_key\"]:\n",
    "    print(\"❌ No API key available. Run the Create Account test first.\")\n",
    "else:\n",
    "    headers = {\"Authorization\": f\"Bearer {GLOBAL_STATE['api_key']}\"}\n",
    "    \n",
    "    start_time = time.time()\n",
    "    successful_submissions = 0\n",
    "    failed_submissions = 0\n",
    "    submission_times = []\n",
    "    \n",
    "    print(f\"Submitting {BULK_SUBMISSION_COUNT} collections...\\n\")\n",
    "    \n",
    "    for i in range(BULK_SUBMISSION_COUNT):\n",
    "        request_data = {\n",
    "            \"label\": f\"Bulk Test #{i+1}\",\n",
    "            \"data\": json.dumps({\n",
    "                \"iteration\": i+1,\n",
    "                \"timestamp\": time.time(),\n",
    "                \"test_type\": \"bulk_submission\"\n",
    "            })\n",
    "        }\n",
    "        \n",
    "        response, elapsed, success = api.request(\"POST\", \"/data/submit\", data=request_data, headers=headers)\n",
    "        submission_times.append(elapsed)\n",
    "        \n",
    "        if success:\n",
    "            successful_submissions += 1\n",
    "            GLOBAL_STATE[\"collection_ids\"].append(response.get(\"collection_id\"))\n",
    "        else:\n",
    "            failed_submissions += 1\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (i + 1) % 10 == 0 or i == BULK_SUBMISSION_COUNT - 1:\n",
    "            progress = (i + 1) / BULK_SUBMISSION_COUNT * 100\n",
    "            print(f\"Progress: {i+1}/{BULK_SUBMISSION_COUNT} ({progress:.1f}%) - \"\n",
    "                  f\"Success: {successful_submissions}, Failed: {failed_submissions}\")\n",
    "    \n",
    "    total_elapsed = time.time() - start_time\n",
    "    avg_time = sum(submission_times) / len(submission_times) if submission_times else 0\n",
    "    throughput = BULK_SUBMISSION_COUNT / total_elapsed if total_elapsed > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"📊 Bulk Submission Summary:\")\n",
    "    print(f\"   Total submissions: {BULK_SUBMISSION_COUNT}\")\n",
    "    print(f\"   Successful: {successful_submissions}\")\n",
    "    print(f\"   Failed: {failed_submissions}\")\n",
    "    print(f\"   Success rate: {successful_submissions/BULK_SUBMISSION_COUNT*100:.1f}%\")\n",
    "    print(f\"   Total time: {total_elapsed:.2f}s\")\n",
    "    print(f\"   Average time per submission: {avg_time:.3f}s\")\n",
    "    print(f\"   Throughput: {throughput:.2f} submissions/second\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    record_test_result(\"Bulk Data Submission\", successful_submissions == BULK_SUBMISSION_COUNT, \n",
    "                      total_elapsed, {\n",
    "                          \"total\": BULK_SUBMISSION_COUNT,\n",
    "                          \"successful\": successful_submissions,\n",
    "                          \"failed\": failed_submissions,\n",
    "                          \"avg_time\": avg_time,\n",
    "                          \"throughput\": throughput\n",
    "                      })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test: List Collections\n",
    "\n",
    "Retrieve all collections for the authenticated user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 5: List Collections\")\n",
    "\n",
    "if not GLOBAL_STATE[\"api_key\"]:\n",
    "    print(\"❌ No API key available. Run the Create Account test first.\")\n",
    "else:\n",
    "    headers = {\"Authorization\": f\"Bearer {GLOBAL_STATE['api_key']}\"}\n",
    "    \n",
    "    response, elapsed, success = api.request(\"GET\", \"/data/list\", headers=headers)\n",
    "    \n",
    "    if success:\n",
    "        collections = response.get(\"collections\", [])\n",
    "        \n",
    "        print(f\"\\n✅ Retrieved {len(collections)} collections\")\n",
    "        \n",
    "        if collections:\n",
    "            # Display as DataFrame\n",
    "            df = pd.DataFrame(collections)\n",
    "            display(df.head(10))\n",
    "            \n",
    "            if len(collections) > 10:\n",
    "                print(f\"\\n... and {len(collections) - 10} more\")\n",
    "    else:\n",
    "        print(f\"\\n❌ Failed to list collections: {response}\")\n",
    "    \n",
    "    record_test_result(\"List Collections\", success, elapsed, {\"count\": len(collections) if success else 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test: Decrypt Collection\n",
    "\n",
    "Decrypt a specific collection to verify data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 6: Decrypt Collection\")\n",
    "\n",
    "if not GLOBAL_STATE[\"api_key\"]:\n",
    "    print(\"❌ No API key available. Run the Create Account test first.\")\n",
    "elif not GLOBAL_STATE[\"collection_ids\"]:\n",
    "    print(\"❌ No collections available. Run the Submit Data test first.\")\n",
    "else:\n",
    "    # Decrypt the first collection\n",
    "    collection_id = GLOBAL_STATE[\"collection_ids\"][0]\n",
    "    headers = {\"Authorization\": f\"Bearer {GLOBAL_STATE['api_key']}\"}\n",
    "    \n",
    "    response, elapsed, success = api.request(\"POST\", f\"/data/decrypt/{collection_id}\", headers=headers)\n",
    "    \n",
    "    if success:\n",
    "        print(f\"\\n✅ Collection decrypted successfully!\")\n",
    "        print(f\"   Collection ID: {response.get('collection_id')}\")\n",
    "        print(f\"   Label: {response.get('label')}\")\n",
    "        print(f\"   Created at: {response.get('created_at')}\")\n",
    "        print(f\"   Data: {response.get('data')}\")\n",
    "    else:\n",
    "        print(f\"\\n❌ Decryption failed: {response}\")\n",
    "    \n",
    "    record_test_result(\"Decrypt Collection\", success, elapsed, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test: View Blockchain\n",
    "\n",
    "Retrieve the entire blockchain state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 7: View Blockchain\")\n",
    "\n",
    "response, elapsed, success = api.request(\"GET\", \"/chain\")\n",
    "\n",
    "if success:\n",
    "    chain_length = len(response.get(\"chain\", []))\n",
    "    node_id = response.get(\"node_id\", \"unknown\")\n",
    "    \n",
    "    print(f\"\\n✅ Blockchain retrieved successfully!\")\n",
    "    print(f\"   Node ID: {node_id}\")\n",
    "    print(f\"   Chain length: {chain_length} blocks\")\n",
    "    \n",
    "    if chain_length > 0:\n",
    "        latest_block = response[\"chain\"][-1]\n",
    "        print(f\"   Latest block index: {latest_block.get('index')}\")\n",
    "        print(f\"   Latest block timestamp: {latest_block.get('timestamp')}\")\n",
    "else:\n",
    "    print(f\"\\n❌ Failed to retrieve blockchain: {response}\")\n",
    "\n",
    "record_test_result(\"View Blockchain\", success, elapsed, {\"chain_length\": chain_length if success else 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test: Chain Statistics\n",
    "\n",
    "Get analytics and statistics about the blockchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 8: Chain Statistics\")\n",
    "\n",
    "response, elapsed, success = api.request(\"GET\", \"/stats\")\n",
    "\n",
    "if success:\n",
    "    print(f\"\\n✅ Statistics retrieved successfully!\")\n",
    "    print(f\"   Total blocks: {response.get('total_blocks')}\")\n",
    "    print(f\"   Total collections: {response.get('total_collections')}\")\n",
    "    print(f\"   Total accounts: {response.get('total_accounts')}\")\n",
    "    print(f\"   Avg block time: {response.get('avg_block_time_seconds', 0):.3f}s\")\n",
    "    \n",
    "    validator_dist = response.get('validator_distribution', {})\n",
    "    if validator_dist:\n",
    "        print(f\"\\n   Validator distribution:\")\n",
    "        for validator, count in validator_dist.items():\n",
    "            print(f\"      {validator}: {count} blocks\")\n",
    "else:\n",
    "    print(f\"\\n❌ Failed to retrieve statistics: {response}\")\n",
    "\n",
    "record_test_result(\"Chain Statistics\", success, elapsed, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Test: Node Metrics\n",
    "\n",
    "Get performance metrics from the current node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 9: Node Metrics\")\n",
    "\n",
    "response, elapsed, success = api.request(\"GET\", \"/metrics\")\n",
    "\n",
    "if success:\n",
    "    print(f\"\\n✅ Metrics retrieved successfully!\")\n",
    "    print(f\"   Node ID: {response.get('node_id')}\")\n",
    "    print(f\"   Chain length: {response.get('chain_length')}\")\n",
    "    print(f\"   Peer count: {response.get('peer_count')}\")\n",
    "    print(f\"   Latest block index: {response.get('latest_block_index')}\")\n",
    "    print(f\"   Latest block timestamp: {response.get('latest_block_timestamp')}\")\n",
    "    print(f\"   Status: {response.get('status')}\")\n",
    "else:\n",
    "    print(f\"\\n❌ Failed to retrieve metrics: {response}\")\n",
    "\n",
    "record_test_result(\"Node Metrics\", success, elapsed, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Test: P2P Peers\n",
    "\n",
    "View connected P2P peers and their reputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 10: P2P Peers\")\n",
    "\n",
    "response, elapsed, success = api.request(\"GET\", \"/peers\")\n",
    "\n",
    "if success:\n",
    "    peers = response.get('peers', [])\n",
    "    reputation = response.get('reputation', {})\n",
    "    \n",
    "    print(f\"\\n✅ Peer information retrieved successfully!\")\n",
    "    print(f\"   Connected peers: {response.get('count', 0)}\")\n",
    "    \n",
    "    if peers:\n",
    "        print(f\"\\n   Peer list:\")\n",
    "        for peer in peers:\n",
    "            rep = reputation.get(peer, 0)\n",
    "            print(f\"      {peer} (reputation: {rep})\")\n",
    "    else:\n",
    "        print(f\"   No peers connected\")\n",
    "else:\n",
    "    print(f\"\\n❌ Failed to retrieve peers: {response}\")\n",
    "\n",
    "record_test_result(\"P2P Peers\", success, elapsed, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Test: Health Check\n",
    "\n",
    "Verify node health status (used by load balancer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Test 11: Health Check\")\n",
    "\n",
    "response, elapsed, success = api.request(\"GET\", \"/health\")\n",
    "\n",
    "if success:\n",
    "    print(f\"\\n✅ Node is healthy!\")\n",
    "    print(f\"   Status: {response.get('status')}\")\n",
    "    print(f\"   Node ID: {response.get('node_id')}\")\n",
    "    print(f\"   Chain length: {response.get('chain_length')}\")\n",
    "    print(f\"   Peer count: {response.get('peer_count')}\")\n",
    "    print(f\"   Latest block: {response.get('latest_block')}\")\n",
    "else:\n",
    "    print(f\"\\n❌ Health check failed: {response}\")\n",
    "\n",
    "record_test_result(\"Health Check\", success, elapsed, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Final Report & Visualizations\n",
    "\n",
    "Generate comprehensive report with timing analysis and charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Final Report & Analysis\")\n",
    "\n",
    "# Calculate summary statistics\n",
    "total_tests = len(GLOBAL_STATE[\"test_results\"])\n",
    "successful_tests = sum(1 for r in GLOBAL_STATE[\"test_results\"] if r[\"success\"])\n",
    "failed_tests = total_tests - successful_tests\n",
    "success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0\n",
    "\n",
    "total_time = sum(r[\"elapsed_seconds\"] for r in GLOBAL_STATE[\"test_results\"])\n",
    "avg_time = total_time / total_tests if total_tests > 0 else 0\n",
    "\n",
    "print(f\"\\n📊 Test Execution Summary:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total tests: {total_tests}\")\n",
    "print(f\"Successful: {successful_tests}\")\n",
    "print(f\"Failed: {failed_tests}\")\n",
    "print(f\"Success rate: {success_rate:.1f}%\")\n",
    "print(f\"Total execution time: {total_time:.2f}s\")\n",
    "print(f\"Average time per test: {avg_time:.3f}s\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Create results DataFrame\n",
    "df_results = pd.DataFrame(GLOBAL_STATE[\"test_results\"])\n",
    "print(\"\\n📋 Detailed Results:\")\n",
    "display(df_results[[\"test_name\", \"success\", \"elapsed_seconds\", \"timestamp\"]])\n",
    "\n",
    "# Export to CSV if configured\n",
    "if EXPORT_TO_CSV:\n",
    "    csv_path = f\"{REPORT_OUTPUT_DIR}test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "    df_results.to_csv(csv_path, index=False)\n",
    "    print(f\"\\n✅ Results exported to: {csv_path}\")\n",
    "\n",
    "# Export to JSON if configured\n",
    "if EXPORT_TO_JSON:\n",
    "    json_path = f\"{REPORT_OUTPUT_DIR}test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump({\n",
    "            \"summary\": {\n",
    "                \"total_tests\": total_tests,\n",
    "                \"successful\": successful_tests,\n",
    "                \"failed\": failed_tests,\n",
    "                \"success_rate\": success_rate,\n",
    "                \"total_time\": total_time,\n",
    "                \"avg_time\": avg_time\n",
    "            },\n",
    "            \"results\": GLOBAL_STATE[\"test_results\"],\n",
    "            \"global_state\": {\n",
    "                \"account_id\": GLOBAL_STATE[\"account_id\"],\n",
    "                \"collection_count\": len(GLOBAL_STATE[\"collection_ids\"])\n",
    "            }\n",
    "        }, f, indent=2)\n",
    "    print(f\"✅ Results exported to: {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate timing charts\n",
    "if GENERATE_CHARTS and GLOBAL_STATE[\"timing_data\"]:\n",
    "    print(\"\\n📊 Generating performance charts...\\n\")\n",
    "    \n",
    "    # Chart 1: Average latency per endpoint\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    endpoints = list(GLOBAL_STATE[\"timing_data\"].keys())\n",
    "    avg_times = [sum(times)/len(times) for times in GLOBAL_STATE[\"timing_data\"].values()]\n",
    "    \n",
    "    ax1.barh(endpoints, avg_times, color='steelblue')\n",
    "    ax1.set_xlabel('Average Response Time (seconds)')\n",
    "    ax1.set_title('Average Latency by Endpoint')\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Chart 2: Response time distribution\n",
    "    all_times = []\n",
    "    all_labels = []\n",
    "    for endpoint, times in GLOBAL_STATE[\"timing_data\"].items():\n",
    "        all_times.extend(times)\n",
    "        all_labels.extend([endpoint] * len(times))\n",
    "    \n",
    "    df_times = pd.DataFrame({'Endpoint': all_labels, 'Time': all_times})\n",
    "    \n",
    "    # Box plot for distribution\n",
    "    sns.boxplot(data=df_times, y='Endpoint', x='Time', ax=ax2)\n",
    "    ax2.set_xlabel('Response Time (seconds)')\n",
    "    ax2.set_title('Response Time Distribution')\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save chart\n",
    "    chart_path = f\"{REPORT_OUTPUT_DIR}performance_chart_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
    "    plt.savefig(chart_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"✅ Chart saved to: {chart_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n✅ Report generation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "All tests completed! Check the cells above for detailed results and the `/scratch` directory for exported reports.\n",
    "\n",
    "**Key Artifacts:**\n",
    "- API Key: Stored in `GLOBAL_STATE[\"api_key\"]`\n",
    "- Collection IDs: Stored in `GLOBAL_STATE[\"collection_ids\"]`\n",
    "- Test Results: Exported to CSV/JSON in `/scratch`\n",
    "- Performance Charts: Saved in `/scratch`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
