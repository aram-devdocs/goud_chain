{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goud Chain API Testing Suite\n",
    "\n",
    "Comprehensive test notebook for all Goud Chain API endpoints with timing metrics and reporting.\n",
    "\n",
    "**Features:**\n",
    "- Create API keys and authenticate\n",
    "- Bulk data submission (configurable batch size)\n",
    "- Collection management and decryption\n",
    "- Blockchain explorer and analytics\n",
    "- Performance metrics with visualizations\n",
    "- Final report generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Adjust these settings before running tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ Configuration ============\n",
    "\n",
    "# API Endpoint (Docker internal network or external)\n",
    "BASE_URL = \"http://nginx:8080\"  # Use this when running notebook in Docker container\n",
    "# BASE_URL = \"http://localhost:8080\"  # Use this for external testing (notebook running on host)\n",
    "\n",
    "# Test Parameters\n",
    "BULK_SUBMISSION_COUNT = 100  # Number of blocks to create in bulk test\n",
    "API_TIMEOUT = 30  # Request timeout in seconds\n",
    "RETRY_ATTEMPTS = 3  # Number of retries for failed requests (can be reduced dynamically if timeouts detected)\n",
    "\n",
    "# Fast-fail mode: reduce retries after detecting server issues\n",
    "ENABLE_FAST_FAIL = True  # Set to False to always retry full number of times\n",
    "\n",
    "# Debug Settings\n",
    "VERBOSE_LOGGING = True  # Print detailed logs\n",
    "SHOW_REQUEST_BODIES = False  # Print full request/response bodies\n",
    "\n",
    "# Report Settings\n",
    "EXPORT_TO_CSV = True  # Export results to CSV\n",
    "EXPORT_TO_JSON = True  # Export results to JSON\n",
    "GENERATE_CHARTS = True  # Generate timing charts\n",
    "\n",
    "# Use home directory which is guaranteed to be writable\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Try multiple possible directories in order of preference\n",
    "possible_dirs = [\n",
    "    \"/work/reports/\",           # If /work is mounted\n",
    "    str(Path.home() / \"reports\"),  # User home directory\n",
    "    \"./reports/\",               # Current directory\n",
    "]\n",
    "\n",
    "REPORT_OUTPUT_DIR = None\n",
    "for dir_path in possible_dirs:\n",
    "    try:\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        # Test write permissions\n",
    "        test_file = os.path.join(dir_path, \".test\")\n",
    "        with open(test_file, 'w') as f:\n",
    "            f.write(\"test\")\n",
    "        os.remove(test_file)\n",
    "        REPORT_OUTPUT_DIR = dir_path\n",
    "        break\n",
    "    except (PermissionError, OSError):\n",
    "        continue\n",
    "\n",
    "if not REPORT_OUTPUT_DIR:\n",
    "    print(\"‚ö†Ô∏è  Warning: Could not create reports directory, using current directory\")\n",
    "    REPORT_OUTPUT_DIR = \"./\"\n",
    "else:\n",
    "    print(f\"‚úÖ Reports directory: {REPORT_OUTPUT_DIR}\")\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"üì° API Endpoint: {BASE_URL}\")\n",
    "print(f\"üî¢ Bulk submission count: {BULK_SUBMISSION_COUNT}\")\n",
    "print(f\"üìÅ Reports will be saved to: {REPORT_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup & Utilities\n",
    "\n",
    "Import libraries and define helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import platform\n",
    "import psutil\n",
    "import socket\n",
    "import sys\n",
    "import traceback\n",
    "import base64\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "from pathlib import Path\n",
    "\n",
    "# Global state storage\n",
    "GLOBAL_STATE = {\n",
    "    \"api_key\": None,\n",
    "    \"account_id\": None,\n",
    "    \"session_token\": None,\n",
    "    \"collection_ids\": [],\n",
    "    \"test_results\": [],\n",
    "    \"timing_data\": {},\n",
    "    \"system_info\": {},\n",
    "    \"server_health_history\": [],\n",
    "    \"failed_dependencies\": set(),\n",
    "    \"timeout_detected\": False,  # Track if we've hit timeouts\n",
    "    \"fast_fail_mode\": False,  # Enable fast-fail after first timeout\n",
    "}\n",
    "\n",
    "# Configure plotting style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "def capture_system_info() -> Dict[str, Any]:\n",
    "    \"\"\"Capture comprehensive system information\"\"\"\n",
    "    try:\n",
    "        cpu_count = psutil.cpu_count(logical=True)\n",
    "        cpu_count_physical = psutil.cpu_count(logical=False)\n",
    "        memory = psutil.virtual_memory()\n",
    "        disk = psutil.disk_usage('/')\n",
    "        \n",
    "        system_info = {\n",
    "            # System basics\n",
    "            \"hostname\": socket.gethostname(),\n",
    "            \"platform\": platform.platform(),\n",
    "            \"platform_system\": platform.system(),\n",
    "            \"platform_release\": platform.release(),\n",
    "            \"platform_version\": platform.version(),\n",
    "            \"architecture\": platform.machine(),\n",
    "            \"processor\": platform.processor(),\n",
    "            \n",
    "            # CPU\n",
    "            \"cpu_count_logical\": cpu_count,\n",
    "            \"cpu_count_physical\": cpu_count_physical,\n",
    "            \"cpu_frequency_mhz\": psutil.cpu_freq().current if psutil.cpu_freq() else \"N/A\",\n",
    "            \"cpu_percent\": psutil.cpu_percent(interval=1),\n",
    "            \n",
    "            # Memory\n",
    "            \"memory_total_gb\": round(memory.total / (1024**3), 2),\n",
    "            \"memory_available_gb\": round(memory.available / (1024**3), 2),\n",
    "            \"memory_used_gb\": round(memory.used / (1024**3), 2),\n",
    "            \"memory_percent\": memory.percent,\n",
    "            \n",
    "            # Disk\n",
    "            \"disk_total_gb\": round(disk.total / (1024**3), 2),\n",
    "            \"disk_used_gb\": round(disk.used / (1024**3), 2),\n",
    "            \"disk_free_gb\": round(disk.free / (1024**3), 2),\n",
    "            \"disk_percent\": disk.percent,\n",
    "            \n",
    "            # Python environment\n",
    "            \"python_version\": sys.version,\n",
    "            \"python_executable\": sys.executable,\n",
    "            \n",
    "            # Network\n",
    "            \"ip_address\": socket.gethostbyname(socket.gethostname()),\n",
    "            \n",
    "            # Timestamp\n",
    "            \"captured_at\": datetime.now().isoformat(),\n",
    "        }\n",
    "        \n",
    "        # Try to get Docker info if running in container\n",
    "        try:\n",
    "            with open('/proc/1/cgroup', 'r') as f:\n",
    "                system_info[\"running_in_docker\"] = 'docker' in f.read()\n",
    "        except:\n",
    "            system_info[\"running_in_docker\"] = False\n",
    "        \n",
    "        return system_info\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to capture system info: {str(e)}\"}\n",
    "\n",
    "def create_download_button(filepath: str, button_text: str = None) -> None:\n",
    "    \"\"\"Create a clickable download button for a file\"\"\"\n",
    "    try:\n",
    "        path = Path(filepath)\n",
    "        if not path.exists():\n",
    "            print(f\"‚ö†Ô∏è  File not found: {filepath}\")\n",
    "            return\n",
    "        \n",
    "        filename = path.name\n",
    "        button_text = button_text or f\"Download {filename}\"\n",
    "        \n",
    "        # Read file and encode as base64\n",
    "        with open(filepath, 'rb') as f:\n",
    "            file_data = f.read()\n",
    "        \n",
    "        b64_data = base64.b64encode(file_data).decode()\n",
    "        \n",
    "        # Create HTML download link styled as a button\n",
    "        file_size_mb = len(file_data) / (1024 * 1024)\n",
    "        html = f'''\n",
    "        <div style=\"margin: 10px 0;\">\n",
    "            <a download=\"{filename}\" \n",
    "               href=\"data:application/octet-stream;base64,{b64_data}\" \n",
    "               style=\"display: inline-block;\n",
    "                      padding: 10px 20px;\n",
    "                      background-color: #4CAF50;\n",
    "                      color: white;\n",
    "                      text-decoration: none;\n",
    "                      border-radius: 5px;\n",
    "                      font-weight: bold;\n",
    "                      font-family: Arial, sans-serif;\n",
    "                      box-shadow: 0 2px 4px rgba(0,0,0,0.2);\n",
    "                      transition: background-color 0.3s;\">\n",
    "                üì• {button_text}\n",
    "            </a>\n",
    "            <span style=\"margin-left: 10px; color: #666; font-size: 0.9em;\">\n",
    "                ({file_size_mb:.2f} MB)\n",
    "            </span>\n",
    "        </div>\n",
    "        <style>\n",
    "            a:hover {{\n",
    "                background-color: #45a049 !important;\n",
    "            }}\n",
    "        </style>\n",
    "        '''\n",
    "        display(HTML(html))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Failed to create download button: {str(e)}\")\n",
    "\n",
    "# Capture system info on startup\n",
    "GLOBAL_STATE[\"system_info\"] = capture_system_info()\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")\n",
    "print(\"‚úÖ Global state initialized\")\n",
    "print(\"‚úÖ System information captured\")\n",
    "print(f\"\\nüìä System Overview:\")\n",
    "print(f\"   Platform: {GLOBAL_STATE['system_info'].get('platform_system')} {GLOBAL_STATE['system_info'].get('platform_release')}\")\n",
    "print(f\"   CPU: {GLOBAL_STATE['system_info'].get('cpu_count_logical')} cores @ {GLOBAL_STATE['system_info'].get('cpu_percent')}% usage\")\n",
    "print(f\"   Memory: {GLOBAL_STATE['system_info'].get('memory_available_gb')} GB available / {GLOBAL_STATE['system_info'].get('memory_total_gb')} GB total\")\n",
    "print(f\"   Disk: {GLOBAL_STATE['system_info'].get('disk_free_gb')} GB free / {GLOBAL_STATE['system_info'].get('disk_total_gb')} GB total\")\n",
    "print(f\"   Python: {sys.version.split()[0]}\")\n",
    "print(f\"   Docker: {'Yes' if GLOBAL_STATE['system_info'].get('running_in_docker') else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ Helper Functions ============\n",
    "\n",
    "class ErrorCategory:\n",
    "    \"\"\"Error type classification\"\"\"\n",
    "    CONNECTION_ERROR = \"connection_error\"\n",
    "    TIMEOUT = \"timeout\"\n",
    "    HTTP_ERROR = \"http_error\"\n",
    "    SERVER_CRASH = \"server_crash\"\n",
    "    JSON_PARSE_ERROR = \"json_parse_error\"\n",
    "    AUTHENTICATION_ERROR = \"authentication_error\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "class ServerHealth:\n",
    "    \"\"\"Server health states\"\"\"\n",
    "    ALIVE = \"alive\"\n",
    "    DEGRADED = \"degraded\"\n",
    "    CRASHED = \"crashed\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "class APIClient:\n",
    "    \"\"\"Wrapper for Goud Chain API calls with timing, error handling, and retry logic\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url: str, timeout: int = 30, retry_attempts: int = 3):\n",
    "        self.base_url = base_url.rstrip('/')\n",
    "        self.timeout = timeout\n",
    "        self.retry_attempts = retry_attempts\n",
    "        self.session = requests.Session()\n",
    "    \n",
    "    def _log(self, message: str, level: str = \"INFO\"):\n",
    "        if VERBOSE_LOGGING or level == \"ERROR\":\n",
    "            timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n",
    "            print(f\"[{timestamp}] {level}: {message}\")\n",
    "    \n",
    "    def check_server_health(self) -> Tuple[str, Dict]:\n",
    "        \"\"\"Check if server is responsive. Returns (health_status, details)\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(f\"{self.base_url}/health\", timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                health_status = ServerHealth.ALIVE\n",
    "                details = {\n",
    "                    \"status\": \"healthy\",\n",
    "                    \"node_id\": data.get(\"node_id\", \"unknown\"),\n",
    "                    \"chain_length\": data.get(\"chain_length\", 0),\n",
    "                    \"peer_count\": data.get(\"peer_count\", 0),\n",
    "                }\n",
    "            else:\n",
    "                health_status = ServerHealth.DEGRADED\n",
    "                details = {\n",
    "                    \"status\": \"degraded\",\n",
    "                    \"http_status\": response.status_code,\n",
    "                    \"error\": response.text[:200]\n",
    "                }\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            health_status = ServerHealth.CRASHED\n",
    "            details = {\"status\": \"crashed\", \"error\": \"Cannot connect to server\"}\n",
    "        except requests.exceptions.Timeout:\n",
    "            health_status = ServerHealth.DEGRADED\n",
    "            details = {\"status\": \"degraded\", \"error\": \"Health check timeout\"}\n",
    "        except Exception as e:\n",
    "            health_status = ServerHealth.UNKNOWN\n",
    "            details = {\"status\": \"unknown\", \"error\": str(e)}\n",
    "        \n",
    "        GLOBAL_STATE[\"server_health_history\"].append({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"health\": health_status,\n",
    "            \"details\": details\n",
    "        })\n",
    "        \n",
    "        return health_status, details\n",
    "    \n",
    "    def request(self, method: str, endpoint: str, data: Optional[Dict] = None, \n",
    "                headers: Optional[Dict] = None, retry: bool = True) -> Tuple[Optional[Dict], float, bool, str, Optional[str]]:\n",
    "        \"\"\"Make HTTP request with timing and retry logic\"\"\"\n",
    "        url = f\"{self.base_url}{endpoint}\"\n",
    "        headers = headers or {}\n",
    "        \n",
    "        if data:\n",
    "            headers[\"Content-Type\"] = \"application/json\"\n",
    "        \n",
    "        # Check fast-fail mode\n",
    "        actual_retries = 1 if (ENABLE_FAST_FAIL and GLOBAL_STATE[\"fast_fail_mode\"]) else (self.retry_attempts if retry else 1)\n",
    "        \n",
    "        retry_count = 0\n",
    "        last_error = None\n",
    "        last_error_category = None\n",
    "        stack_trace = None\n",
    "        \n",
    "        while retry_count < actual_retries:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                self._log(f\"{method} {endpoint} (attempt {retry_count + 1}/{actual_retries})\")\n",
    "                \n",
    "                if method == \"GET\":\n",
    "                    response = self.session.get(url, headers=headers, timeout=self.timeout)\n",
    "                elif method == \"POST\":\n",
    "                    response = self.session.post(url, json=data, headers=headers, timeout=self.timeout)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported method: {method}\")\n",
    "                \n",
    "                elapsed = time.time() - start_time\n",
    "                \n",
    "                if response.status_code >= 200 and response.status_code < 300:\n",
    "                    try:\n",
    "                        result = response.json() if response.content else {}\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        self._log(f\"‚ùå JSON parse error: {str(e)}\", \"ERROR\")\n",
    "                        return {\"error\": \"Invalid JSON response\"}, elapsed, False, ErrorCategory.JSON_PARSE_ERROR, traceback.format_exc()\n",
    "                    \n",
    "                    self._log(f\"‚úÖ Success ({response.status_code}) in {elapsed:.3f}s\")\n",
    "                    return result, elapsed, True, None, None\n",
    "                else:\n",
    "                    self._log(f\"‚ùå Failed ({response.status_code}): {response.text[:200]}\", \"ERROR\")\n",
    "                    error_category = ErrorCategory.HTTP_ERROR\n",
    "                    if response.status_code == 401 or response.status_code == 403:\n",
    "                        error_category = ErrorCategory.AUTHENTICATION_ERROR\n",
    "                    return {\"error\": response.text, \"status_code\": response.status_code}, elapsed, False, error_category, None\n",
    "            \n",
    "            except requests.exceptions.ConnectionError as e:\n",
    "                elapsed = time.time() - start_time\n",
    "                last_error = e\n",
    "                last_error_category = ErrorCategory.CONNECTION_ERROR\n",
    "                stack_trace = traceback.format_exc()\n",
    "                self._log(f\"‚ùå Connection error: {str(e)}\", \"ERROR\")\n",
    "            \n",
    "            except requests.exceptions.Timeout as e:\n",
    "                elapsed = time.time() - start_time\n",
    "                last_error = e\n",
    "                last_error_category = ErrorCategory.TIMEOUT\n",
    "                stack_trace = traceback.format_exc()\n",
    "                self._log(f\"‚ùå Timeout after {elapsed:.3f}s\", \"ERROR\")\n",
    "                \n",
    "                # Enable fast-fail mode after first timeout\n",
    "                if ENABLE_FAST_FAIL and not GLOBAL_STATE[\"fast_fail_mode\"]:\n",
    "                    GLOBAL_STATE[\"fast_fail_mode\"] = True\n",
    "                    print(f\"\\n‚ö° Fast-fail mode enabled: future tests will skip retries\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                elapsed = time.time() - start_time\n",
    "                last_error = e\n",
    "                last_error_category = ErrorCategory.UNKNOWN\n",
    "                stack_trace = traceback.format_exc()\n",
    "                self._log(f\"‚ùå Exception: {str(e)}\", \"ERROR\")\n",
    "            \n",
    "            retry_count += 1\n",
    "            \n",
    "            if retry_count < actual_retries and retry:\n",
    "                backoff = min(2 ** retry_count, 10)\n",
    "                self._log(f\"‚è≥ Retrying in {backoff}s...\")\n",
    "                time.sleep(backoff)\n",
    "        \n",
    "        return {\n",
    "            \"error\": str(last_error) if last_error else \"Unknown error\",\n",
    "            \"retry_count\": retry_count\n",
    "        }, elapsed, False, last_error_category or ErrorCategory.UNKNOWN, stack_trace\n",
    "\n",
    "def record_test_result(test_name: str, success: bool, elapsed: float, details: Dict = None, \n",
    "                      error_category: Optional[str] = None, stack_trace: Optional[str] = None,\n",
    "                      skipped: bool = False, skip_reason: Optional[str] = None, retry_count: int = 0):\n",
    "    \"\"\"Record test result for final report\"\"\"\n",
    "    server_health = GLOBAL_STATE[\"server_health_history\"][-1][\"health\"] if GLOBAL_STATE[\"server_health_history\"] else ServerHealth.UNKNOWN\n",
    "    \n",
    "    result = {\n",
    "        \"test_name\": test_name,\n",
    "        \"success\": success,\n",
    "        \"elapsed_seconds\": elapsed,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"details\": details or {},\n",
    "        \"error_category\": error_category,\n",
    "        \"stack_trace\": stack_trace,\n",
    "        \"skipped\": skipped,\n",
    "        \"skip_reason\": skip_reason,\n",
    "        \"retry_count\": retry_count,\n",
    "        \"server_health\": server_health,\n",
    "    }\n",
    "    GLOBAL_STATE[\"test_results\"].append(result)\n",
    "    \n",
    "    if success and not skipped:\n",
    "        if test_name not in GLOBAL_STATE[\"timing_data\"]:\n",
    "            GLOBAL_STATE[\"timing_data\"][test_name] = []\n",
    "        GLOBAL_STATE[\"timing_data\"][test_name].append(elapsed)\n",
    "    \n",
    "    if not success and not skipped:\n",
    "        GLOBAL_STATE[\"failed_dependencies\"].add(test_name)\n",
    "\n",
    "def run_api_test(test_name: str, method: str, endpoint: str, \n",
    "                 data: Optional[Dict] = None, headers: Optional[Dict] = None,\n",
    "                 dependencies: List[str] = None, \n",
    "                 on_success = None, on_failure = None,\n",
    "                 skip_health_check: bool = False) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Universal test runner - eliminates code duplication across test cells.\n",
    "    \n",
    "    Args:\n",
    "        test_name: Display name for the test\n",
    "        method: HTTP method (GET or POST)\n",
    "        endpoint: API endpoint to test\n",
    "        data: Request body (for POST)\n",
    "        headers: Request headers\n",
    "        dependencies: List of test names this test depends on\n",
    "        on_success: Callback function(response) to handle successful response\n",
    "        on_failure: Callback function(response, error_category) to handle failure\n",
    "        skip_health_check: If True, don't check server health before test\n",
    "    \n",
    "    Returns:\n",
    "        API response dict if successful, None otherwise\n",
    "    \"\"\"\n",
    "    print_section(test_name)\n",
    "    \n",
    "    try:\n",
    "        # Check dependencies\n",
    "        dependencies = dependencies or []\n",
    "        for dep in dependencies:\n",
    "            if dep in GLOBAL_STATE[\"failed_dependencies\"]:\n",
    "                print(f\"\\n‚è≠Ô∏è  Test skipped: Dependency failed: {dep}\")\n",
    "                record_test_result(test_name, False, 0, skipped=True, skip_reason=f\"Dependency failed: {dep}\")\n",
    "                return None\n",
    "        \n",
    "        # Check server health (unless skipped)\n",
    "        if not skip_health_check:\n",
    "            print(\"üè• Checking server health...\")\n",
    "            health, health_details = api.check_server_health()\n",
    "            print(f\"   Server status: {health} - {health_details.get('status', 'unknown')}\")\n",
    "            \n",
    "            if health == ServerHealth.CRASHED or (GLOBAL_STATE[\"fast_fail_mode\"] and health == ServerHealth.DEGRADED):\n",
    "                print(f\"\\nüíÄ Server {'crashed' if health == ServerHealth.CRASHED else 'degraded'}! Skipping test.\")\n",
    "                record_test_result(test_name, False, 0, \n",
    "                                  details={\"server_crashed\": health == ServerHealth.CRASHED}, \n",
    "                                  error_category=ErrorCategory.SERVER_CRASH if health == ServerHealth.CRASHED else ErrorCategory.TIMEOUT,\n",
    "                                  skipped=True,\n",
    "                                  skip_reason=f\"Server {health}\")\n",
    "                return None\n",
    "        \n",
    "        # Make API request\n",
    "        response, elapsed, success, error_category, stack_trace = api.request(method, endpoint, data=data, headers=headers)\n",
    "        \n",
    "        # Handle result\n",
    "        if success:\n",
    "            print(f\"\\n‚úÖ Success!\")\n",
    "            if on_success:\n",
    "                on_success(response)\n",
    "            record_test_result(test_name, True, elapsed, response, error_category=error_category, stack_trace=stack_trace)\n",
    "            return response\n",
    "        else:\n",
    "            print(f\"\\n‚ùå Failed: {response.get('error', 'Unknown error')}\")\n",
    "            print(f\"   Error category: {error_category}\")\n",
    "            if on_failure:\n",
    "                on_failure(response, error_category)\n",
    "            record_test_result(test_name, False, elapsed, response, error_category=error_category, stack_trace=stack_trace)\n",
    "            return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nüí• UNHANDLED EXCEPTION: {str(e)}\")\n",
    "        stack = traceback.format_exc()\n",
    "        if VERBOSE_LOGGING:\n",
    "            print(f\"   Stack trace:\\n{stack}\")\n",
    "        record_test_result(test_name, False, 0,\n",
    "                          details={\"unhandled_exception\": str(e)},\n",
    "                          error_category=ErrorCategory.UNKNOWN,\n",
    "                          stack_trace=stack)\n",
    "        return None\n",
    "\n",
    "def print_section(title: str):\n",
    "    \"\"\"Print formatted section header\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {title}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Initialize API client\n",
    "api = APIClient(BASE_URL, API_TIMEOUT, RETRY_ATTEMPTS)\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")\n",
    "print(\"‚úÖ API client initialized\")\n",
    "print(f\"   Max retries: {RETRY_ATTEMPTS}\")\n",
    "print(f\"   Timeout: {API_TIMEOUT}s\")\n",
    "print(f\"   Fast-fail: {'Enabled' if ENABLE_FAST_FAIL else 'Disabled'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test: Create Account\n",
    "\n",
    "Create a new user account and obtain an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Create Account\n",
    "def handle_create_account_success(response):\n",
    "    GLOBAL_STATE[\"api_key\"] = response.get(\"api_key\")\n",
    "    GLOBAL_STATE[\"account_id\"] = response.get(\"account_id\")\n",
    "    print(f\"   Account ID: {GLOBAL_STATE['account_id']}\")\n",
    "    print(f\"   API Key: {GLOBAL_STATE['api_key'][:20]}...\" if GLOBAL_STATE['api_key'] else \"   API Key: None\")\n",
    "    if response.get('warning'):\n",
    "        print(f\"\\n‚ö†Ô∏è  {response.get('warning')}\")\n",
    "\n",
    "run_api_test(\n",
    "    test_name=\"Test 1: Create Account\",\n",
    "    method=\"POST\",\n",
    "    endpoint=\"/account/create\",\n",
    "    data={\"metadata\": \"Test account created from Jupyter notebook\"},\n",
    "    on_success=handle_create_account_success\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test: Login\n",
    "\n",
    "Login with API key to obtain a session token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Login\n",
    "def handle_login_success(response):\n",
    "    GLOBAL_STATE[\"session_token\"] = response.get(\"session_token\")\n",
    "    print(f\"   Session Token: {GLOBAL_STATE['session_token'][:30]}...\" if GLOBAL_STATE['session_token'] else \"   Session Token: None\")\n",
    "    print(f\"   Expires in: {response.get('expires_in')} seconds\")\n",
    "\n",
    "run_api_test(\n",
    "    test_name=\"Test 2: Login\",\n",
    "    method=\"POST\",\n",
    "    endpoint=\"/account/login\",\n",
    "    data={\"api_key\": GLOBAL_STATE[\"api_key\"]},\n",
    "    dependencies=[\"Test 1: Create Account\"],\n",
    "    on_success=handle_login_success\n",
    ") if GLOBAL_STATE[\"api_key\"] else print(\"‚è≠Ô∏è  Skipped: No API key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test: Submit Data (Single)\n",
    "\n",
    "Submit a single encrypted collection to the blockchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Submit Data (Single)\n",
    "def handle_submit_success(response):\n",
    "    collection_id = response.get(\"collection_id\")\n",
    "    if collection_id:\n",
    "        GLOBAL_STATE[\"collection_ids\"].append(collection_id)\n",
    "    print(f\"   Collection ID: {collection_id}\")\n",
    "    print(f\"   Block Number: {response.get('block_number')}\")\n",
    "    print(f\"   Message: {response.get('message')}\")\n",
    "\n",
    "run_api_test(\n",
    "    test_name=\"Test 3: Submit Data (Single)\",\n",
    "    method=\"POST\",\n",
    "    endpoint=\"/data/submit\",\n",
    "    data={\n",
    "        \"label\": \"Test Collection\",\n",
    "        \"data\": json.dumps({\"message\": \"Hello from Jupyter!\", \"timestamp\": time.time()})\n",
    "    },\n",
    "    headers={\"Authorization\": f\"Bearer {GLOBAL_STATE['api_key']}\"},\n",
    "    dependencies=[\"Test 1: Create Account\"],\n",
    "    on_success=handle_submit_success\n",
    ") if GLOBAL_STATE[\"api_key\"] else print(\"‚è≠Ô∏è  Skipped: No API key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test: Bulk Data Submission\n",
    "\n",
    "Submit multiple collections to test throughput and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Bulk Data Submission\n",
    "print_section(f\"Test 4: Bulk Data Submission ({BULK_SUBMISSION_COUNT} blocks)\")\n",
    "\n",
    "if not GLOBAL_STATE[\"api_key\"]:\n",
    "    print(\"‚è≠Ô∏è  Skipped: No API key\")\n",
    "    record_test_result(\"Test 4: Bulk Data Submission\", False, 0, skipped=True, skip_reason=\"No API key\")\n",
    "else:\n",
    "    try:\n",
    "        print(\"üè• Checking server health before bulk test...\")\n",
    "        health, health_details = api.check_server_health()\n",
    "        print(f\"   Server status: {health} - {health_details.get('status', 'unknown')}\")\n",
    "        \n",
    "        if health == ServerHealth.CRASHED:\n",
    "            print(\"\\nüíÄ Server crashed! Skipping bulk test.\")\n",
    "            record_test_result(\"Test 4: Bulk Data Submission\", False, 0, \n",
    "                              details={\"server_crashed\": True}, \n",
    "                              error_category=ErrorCategory.SERVER_CRASH,\n",
    "                              skipped=True, skip_reason=\"Server crashed\")\n",
    "        else:\n",
    "            headers = {\"Authorization\": f\"Bearer {GLOBAL_STATE['api_key']}\"}\n",
    "            start_time = time.time()\n",
    "            successful = 0\n",
    "            failed = 0\n",
    "            submission_times = []\n",
    "            error_counts = {}\n",
    "            server_crashed = False\n",
    "            \n",
    "            print(f\"Submitting {BULK_SUBMISSION_COUNT} collections...\\n\")\n",
    "            \n",
    "            for i in range(BULK_SUBMISSION_COUNT):\n",
    "                # Check health every 50 iterations\n",
    "                if i > 0 and i % 50 == 0:\n",
    "                    health, _ = api.check_server_health()\n",
    "                    if health == ServerHealth.CRASHED:\n",
    "                        print(f\"\\nüíÄ Server crashed at iteration {i}!\")\n",
    "                        server_crashed = True\n",
    "                        break\n",
    "                \n",
    "                data = {\n",
    "                    \"label\": f\"Bulk Test #{i+1}\",\n",
    "                    \"data\": json.dumps({\"iteration\": i+1, \"timestamp\": time.time(), \"test_type\": \"bulk\"})\n",
    "                }\n",
    "                \n",
    "                response, elapsed, success, error_category, _ = api.request(\"POST\", \"/data/submit\", data=data, headers=headers, retry=False)\n",
    "                submission_times.append(elapsed)\n",
    "                \n",
    "                if success:\n",
    "                    successful += 1\n",
    "                    if response.get(\"collection_id\"):\n",
    "                        GLOBAL_STATE[\"collection_ids\"].append(response[\"collection_id\"])\n",
    "                else:\n",
    "                    failed += 1\n",
    "                    if error_category:\n",
    "                        error_counts[error_category] = error_counts.get(error_category, 0) + 1\n",
    "                    if error_category == ErrorCategory.SERVER_CRASH:\n",
    "                        print(f\"\\nüíÄ Server crashed at iteration {i+1}!\")\n",
    "                        server_crashed = True\n",
    "                        break\n",
    "                \n",
    "                # Progress indicator\n",
    "                if (i + 1) % 10 == 0 or i == BULK_SUBMISSION_COUNT - 1:\n",
    "                    progress = (i + 1) / BULK_SUBMISSION_COUNT * 100\n",
    "                    print(f\"Progress: {i+1}/{BULK_SUBMISSION_COUNT} ({progress:.1f}%) - Success: {successful}, Failed: {failed}\")\n",
    "            \n",
    "            total_time = time.time() - start_time\n",
    "            avg_time = sum(submission_times) / len(submission_times) if submission_times else 0\n",
    "            throughput = successful / total_time if total_time > 0 else 0\n",
    "            \n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"üìä Bulk Submission Summary:\")\n",
    "            print(f\"   Total attempted: {successful + failed}\")\n",
    "            print(f\"   Successful: {successful}\")\n",
    "            print(f\"   Failed: {failed}\")\n",
    "            print(f\"   Success rate: {successful/(successful + failed)*100:.1f}%\" if (successful + failed) > 0 else \"   Success rate: N/A\")\n",
    "            print(f\"   Total time: {total_time:.2f}s\")\n",
    "            print(f\"   Average time: {avg_time:.3f}s\")\n",
    "            print(f\"   Throughput: {throughput:.2f} submissions/second\")\n",
    "            if server_crashed:\n",
    "                print(f\"   ‚ö†Ô∏è  SERVER CRASHED during test!\")\n",
    "            if error_counts:\n",
    "                print(f\"   Error categories:\")\n",
    "                for cat, count in error_counts.items():\n",
    "                    print(f\"      {cat}: {count}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            test_success = successful == BULK_SUBMISSION_COUNT and not server_crashed\n",
    "            \n",
    "            record_test_result(\"Test 4: Bulk Data Submission\", test_success, total_time, {\n",
    "                \"total_attempted\": successful + failed,\n",
    "                \"target\": BULK_SUBMISSION_COUNT,\n",
    "                \"successful\": successful,\n",
    "                \"failed\": failed,\n",
    "                \"avg_time\": avg_time,\n",
    "                \"throughput\": throughput,\n",
    "                \"server_crashed\": server_crashed,\n",
    "                \"error_categories\": error_counts\n",
    "            }, error_category=ErrorCategory.SERVER_CRASH if server_crashed else None)\n",
    "            \n",
    "            # Enable fast-fail if we hit issues\n",
    "            if failed > 0 and ENABLE_FAST_FAIL:\n",
    "                GLOBAL_STATE[\"fast_fail_mode\"] = True\n",
    "                print(f\"\\n‚ö° Fast-fail mode enabled due to bulk test failures\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nüí• UNHANDLED EXCEPTION: {str(e)}\")\n",
    "        record_test_result(\"Test 4: Bulk Data Submission\", False, 0,\n",
    "                          details={\"unhandled_exception\": str(e)},\n",
    "                          error_category=ErrorCategory.UNKNOWN,\n",
    "                          stack_trace=traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test: List Collections\n",
    "\n",
    "Retrieve all collections for the authenticated user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 5: List Collections\n",
    "def handle_list_success(response):\n",
    "    collections = response.get(\"collections\", [])\n",
    "    print(f\"   Retrieved {len(collections)} collections\")\n",
    "    if collections:\n",
    "        try:\n",
    "            df = pd.DataFrame(collections)\n",
    "            display(df.head(10))\n",
    "            if len(collections) > 10:\n",
    "                print(f\"\\n... and {len(collections) - 10} more\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Could not display as DataFrame: {str(e)}\")\n",
    "            print(f\"   Raw data: {collections[:3]}\")\n",
    "\n",
    "run_api_test(\n",
    "    test_name=\"Test 5: List Collections\",\n",
    "    method=\"GET\",\n",
    "    endpoint=\"/data/list\",\n",
    "    headers={\"Authorization\": f\"Bearer {GLOBAL_STATE['api_key']}\"},\n",
    "    dependencies=[\"Test 1: Create Account\"],\n",
    "    on_success=handle_list_success\n",
    ") if GLOBAL_STATE[\"api_key\"] else print(\"‚è≠Ô∏è  Skipped: No API key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test: Decrypt Collection\n",
    "\n",
    "Decrypt a specific collection to verify data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 6: Decrypt Collection\n",
    "def handle_decrypt_success(response):\n",
    "    print(f\"   Collection ID: {response.get('collection_id')}\")\n",
    "    print(f\"   Label: {response.get('label')}\")\n",
    "    print(f\"   Created at: {response.get('created_at')}\")\n",
    "    print(f\"   Data: {response.get('data')}\")\n",
    "\n",
    "if not GLOBAL_STATE[\"api_key\"]:\n",
    "    print(\"‚è≠Ô∏è  Skipped: No API key\")\n",
    "elif not GLOBAL_STATE[\"collection_ids\"]:\n",
    "    print(\"‚è≠Ô∏è  Skipped: No collections available\")\n",
    "else:\n",
    "    collection_id = GLOBAL_STATE[\"collection_ids\"][0]\n",
    "    run_api_test(\n",
    "        test_name=\"Test 6: Decrypt Collection\",\n",
    "        method=\"POST\",\n",
    "        endpoint=f\"/data/decrypt/{collection_id}\",\n",
    "        headers={\"Authorization\": f\"Bearer {GLOBAL_STATE['api_key']}\"},\n",
    "        dependencies=[\"Test 1: Create Account\", \"Test 3: Submit Data (Single)\"],\n",
    "        on_success=handle_decrypt_success\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test: View Blockchain\n",
    "\n",
    "Retrieve the entire blockchain state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 7: View Blockchain\n",
    "def handle_blockchain_success(response):\n",
    "    chain_length = len(response.get(\"chain\", []))\n",
    "    node_id = response.get(\"node_id\", \"unknown\")\n",
    "    print(f\"   Node ID: {node_id}\")\n",
    "    print(f\"   Chain length: {chain_length} blocks\")\n",
    "    if chain_length > 0:\n",
    "        try:\n",
    "            latest_block = response[\"chain\"][-1]\n",
    "            print(f\"   Latest block index: {latest_block.get('index')}\")\n",
    "            print(f\"   Latest block timestamp: {latest_block.get('timestamp')}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Could not parse latest block: {str(e)}\")\n",
    "\n",
    "run_api_test(\n",
    "    test_name=\"Test 7: View Blockchain\",\n",
    "    method=\"GET\",\n",
    "    endpoint=\"/chain\",\n",
    "    on_success=handle_blockchain_success\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test: Chain Statistics\n",
    "\n",
    "Get analytics and statistics about the blockchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 8: Chain Statistics\n",
    "def handle_stats_success(response):\n",
    "    print(f\"   Total blocks: {response.get('total_blocks')}\")\n",
    "    print(f\"   Total collections: {response.get('total_collections')}\")\n",
    "    print(f\"   Total accounts: {response.get('total_accounts')}\")\n",
    "    print(f\"   Avg block time: {response.get('avg_block_time_seconds', 0):.3f}s\")\n",
    "    \n",
    "    validator_dist = response.get('validator_distribution', {})\n",
    "    if validator_dist:\n",
    "        print(f\"\\n   Validator distribution:\")\n",
    "        for validator, count in validator_dist.items():\n",
    "            print(f\"      {validator}: {count} blocks\")\n",
    "\n",
    "run_api_test(\n",
    "    test_name=\"Test 8: Chain Statistics\",\n",
    "    method=\"GET\",\n",
    "    endpoint=\"/stats\",\n",
    "    on_success=handle_stats_success\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Test: Node Metrics\n",
    "\n",
    "Get performance metrics from the current node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 9: Node Metrics\n",
    "def handle_metrics_success(response):\n",
    "    print(f\"   Node ID: {response.get('node_id')}\")\n",
    "    print(f\"   Chain length: {response.get('chain_length')}\")\n",
    "    print(f\"   Peer count: {response.get('peer_count')}\")\n",
    "    print(f\"   Latest block index: {response.get('latest_block_index')}\")\n",
    "    print(f\"   Latest block timestamp: {response.get('latest_block_timestamp')}\")\n",
    "    print(f\"   Status: {response.get('status')}\")\n",
    "\n",
    "run_api_test(\n",
    "    test_name=\"Test 9: Node Metrics\",\n",
    "    method=\"GET\",\n",
    "    endpoint=\"/metrics\",\n",
    "    on_success=handle_metrics_success\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Test: P2P Peers\n",
    "\n",
    "View connected P2P peers and their reputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 10: P2P Peers\n",
    "def handle_peers_success(response):\n",
    "    peers = response.get('peers', [])\n",
    "    reputation = response.get('reputation', {})\n",
    "    print(f\"   Connected peers: {response.get('count', 0)}\")\n",
    "    if peers:\n",
    "        print(f\"\\n   Peer list:\")\n",
    "        for peer in peers:\n",
    "            rep = reputation.get(peer, 0)\n",
    "            print(f\"      {peer} (reputation: {rep})\")\n",
    "    else:\n",
    "        print(f\"   No peers connected\")\n",
    "\n",
    "run_api_test(\n",
    "    test_name=\"Test 10: P2P Peers\",\n",
    "    method=\"GET\",\n",
    "    endpoint=\"/peers\",\n",
    "    on_success=handle_peers_success\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Test: Health Check\n",
    "\n",
    "Verify node health status (used by load balancer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 11: Health Check\n",
    "def handle_health_success(response):\n",
    "    print(f\"   Status: {response.get('status')}\")\n",
    "    print(f\"   Node ID: {response.get('node_id')}\")\n",
    "    print(f\"   Chain length: {response.get('chain_length')}\")\n",
    "    print(f\"   Peer count: {response.get('peer_count')}\")\n",
    "    print(f\"   Latest block: {response.get('latest_block')}\")\n",
    "\n",
    "def handle_health_failure(response, error_category):\n",
    "    print(f\"   This indicates the server is crashed, degraded, or experiencing issues\")\n",
    "\n",
    "run_api_test(\n",
    "    test_name=\"Test 11: Health Check\",\n",
    "    method=\"GET\",\n",
    "    endpoint=\"/health\",\n",
    "    skip_health_check=True,  # Don't check health before the health check itself\n",
    "    on_success=handle_health_success,\n",
    "    on_failure=handle_health_failure\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Final Report & Visualizations\n",
    "\n",
    "Generate comprehensive report with timing analysis and charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section(\"Final Report & Analysis\")\n",
    "\n",
    "try:\n",
    "    # Calculate summary statistics\n",
    "    total_tests = len(GLOBAL_STATE[\"test_results\"])\n",
    "    successful_tests = sum(1 for r in GLOBAL_STATE[\"test_results\"] if r[\"success\"] and not r.get(\"skipped\"))\n",
    "    failed_tests = sum(1 for r in GLOBAL_STATE[\"test_results\"] if not r[\"success\"] and not r.get(\"skipped\"))\n",
    "    skipped_tests = sum(1 for r in GLOBAL_STATE[\"test_results\"] if r.get(\"skipped\"))\n",
    "    success_rate = (successful_tests / (successful_tests + failed_tests) * 100) if (successful_tests + failed_tests) > 0 else 0\n",
    "    \n",
    "    total_time = sum(r[\"elapsed_seconds\"] for r in GLOBAL_STATE[\"test_results\"])\n",
    "    avg_time = total_time / total_tests if total_tests > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüìä Test Execution Summary:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total tests: {total_tests}\")\n",
    "    print(f\"Successful: {successful_tests}\")\n",
    "    print(f\"Failed: {failed_tests}\")\n",
    "    print(f\"Skipped: {skipped_tests}\")\n",
    "    print(f\"Success rate: {success_rate:.1f}% (excluding skipped)\")\n",
    "    print(f\"Total execution time: {total_time:.2f}s ({total_time/60:.1f} minutes)\")\n",
    "    print(f\"Average time per test: {avg_time:.3f}s\")\n",
    "    if GLOBAL_STATE[\"fast_fail_mode\"]:\n",
    "        print(f\"‚ö° Fast-fail mode: Enabled (retries skipped after timeouts detected)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Error category analysis\n",
    "    error_categories = {}\n",
    "    for result in GLOBAL_STATE[\"test_results\"]:\n",
    "        if result.get(\"error_category\"):\n",
    "            cat = result[\"error_category\"]\n",
    "            error_categories[cat] = error_categories.get(cat, 0) + 1\n",
    "    \n",
    "    if error_categories:\n",
    "        print(f\"\\nüîç Error Category Breakdown:\")\n",
    "        print(f\"{'='*60}\")\n",
    "        for category, count in sorted(error_categories.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"   {category}: {count} occurrences\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Server health timeline\n",
    "    if GLOBAL_STATE[\"server_health_history\"]:\n",
    "        print(f\"\\nüè• Server Health Timeline:\")\n",
    "        print(f\"{'='*60}\")\n",
    "        health_counts = {}\n",
    "        for entry in GLOBAL_STATE[\"server_health_history\"]:\n",
    "            health = entry[\"health\"]\n",
    "            health_counts[health] = health_counts.get(health, 0) + 1\n",
    "        \n",
    "        for health, count in sorted(health_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"   {health}: {count} checks\")\n",
    "        \n",
    "        crashes = [e for e in GLOBAL_STATE[\"server_health_history\"] if e[\"health\"] == ServerHealth.CRASHED]\n",
    "        if crashes:\n",
    "            print(f\"\\n   ‚ö†Ô∏è  SERVER CRASHES DETECTED: {len(crashes)} times\")\n",
    "            print(f\"   First crash at: {crashes[0]['timestamp']}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Dependency chain analysis\n",
    "    if GLOBAL_STATE[\"failed_dependencies\"]:\n",
    "        print(f\"\\nüîó Failed Dependencies (blocking downstream tests):\")\n",
    "        print(f\"{'='*60}\")\n",
    "        for dep in GLOBAL_STATE[\"failed_dependencies\"]:\n",
    "            blocked_tests = [r for r in GLOBAL_STATE[\"test_results\"] \n",
    "                           if r.get(\"skip_reason\") and dep in r.get(\"skip_reason\", \"\")]\n",
    "            print(f\"   '{dep}' blocked {len(blocked_tests)} downstream test(s)\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    df_results = pd.DataFrame(GLOBAL_STATE[\"test_results\"])\n",
    "    \n",
    "    print(\"\\nüìã Detailed Results:\")\n",
    "    display_cols = [\"test_name\", \"success\", \"skipped\", \"elapsed_seconds\", \"error_category\", \"server_health\"]\n",
    "    if all(col in df_results.columns for col in display_cols):\n",
    "        display(df_results[display_cols])\n",
    "    else:\n",
    "        display(df_results)\n",
    "    \n",
    "    # Export files and create download buttons\n",
    "    export_files = []\n",
    "    \n",
    "    # Export to CSV\n",
    "    if EXPORT_TO_CSV:\n",
    "        try:\n",
    "            csv_path = f\"{REPORT_OUTPUT_DIR}test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "            df_results.to_csv(csv_path, index=False)\n",
    "            print(f\"\\n‚úÖ CSV exported to: {csv_path}\")\n",
    "            export_files.append((\"CSV\", csv_path))\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ö†Ô∏è  Failed to export CSV: {str(e)}\")\n",
    "    \n",
    "    # Export to JSON\n",
    "    if EXPORT_TO_JSON:\n",
    "        try:\n",
    "            json_path = f\"{REPORT_OUTPUT_DIR}test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "            with open(json_path, 'w') as f:\n",
    "                json.dump({\n",
    "                    \"test_run_info\": {\n",
    "                        \"timestamp\": datetime.now().isoformat(),\n",
    "                        \"base_url\": BASE_URL,\n",
    "                        \"bulk_submission_count\": BULK_SUBMISSION_COUNT,\n",
    "                        \"api_timeout\": API_TIMEOUT,\n",
    "                        \"retry_attempts\": RETRY_ATTEMPTS,\n",
    "                        \"fast_fail_enabled\": ENABLE_FAST_FAIL,\n",
    "                        \"fast_fail_triggered\": GLOBAL_STATE[\"fast_fail_mode\"],\n",
    "                    },\n",
    "                    \"system_info\": GLOBAL_STATE[\"system_info\"],\n",
    "                    \"summary\": {\n",
    "                        \"total_tests\": total_tests,\n",
    "                        \"successful\": successful_tests,\n",
    "                        \"failed\": failed_tests,\n",
    "                        \"skipped\": skipped_tests,\n",
    "                        \"success_rate\": success_rate,\n",
    "                        \"total_time\": total_time,\n",
    "                        \"avg_time\": avg_time,\n",
    "                        \"error_categories\": error_categories,\n",
    "                    },\n",
    "                    \"server_health_summary\": {\n",
    "                        \"total_checks\": len(GLOBAL_STATE[\"server_health_history\"]),\n",
    "                        \"crash_count\": len([e for e in GLOBAL_STATE[\"server_health_history\"] if e[\"health\"] == ServerHealth.CRASHED]),\n",
    "                        \"timeline\": GLOBAL_STATE[\"server_health_history\"],\n",
    "                    },\n",
    "                    \"results\": GLOBAL_STATE[\"test_results\"],\n",
    "                    \"global_state\": {\n",
    "                        \"account_id\": GLOBAL_STATE[\"account_id\"],\n",
    "                        \"collection_count\": len(GLOBAL_STATE[\"collection_ids\"]),\n",
    "                        \"failed_dependencies\": list(GLOBAL_STATE[\"failed_dependencies\"]),\n",
    "                    }\n",
    "                }, f, indent=2)\n",
    "            print(f\"‚úÖ JSON exported to: {json_path}\")\n",
    "            export_files.append((\"JSON\", json_path))\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ö†Ô∏è  Failed to export JSON: {str(e)}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\nüí° Recommendations:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if failed_tests == 0 and skipped_tests == 0:\n",
    "        print(\"   ‚úÖ All tests passed! System is healthy.\")\n",
    "    else:\n",
    "        if ErrorCategory.SERVER_CRASH in error_categories:\n",
    "            print(\"   üö® Server crashed during testing - check memory limits and logs\")\n",
    "        if ErrorCategory.TIMEOUT in error_categories:\n",
    "            print(\"   ‚è±Ô∏è  Timeouts detected - server may be overloaded or unresponsive\")\n",
    "        if ErrorCategory.CONNECTION_ERROR in error_categories:\n",
    "            print(\"   üîå Connection errors detected - verify network configuration\")\n",
    "        if skipped_tests > 0:\n",
    "            print(f\"   ‚è≠Ô∏è  {skipped_tests} tests skipped - fix root causes first\")\n",
    "        if failed_tests > successful_tests:\n",
    "            print(\"   üî• More failures than successes - system may be fundamentally broken\")\n",
    "        if GLOBAL_STATE[\"fast_fail_mode\"]:\n",
    "            print(f\"   ‚ö° Fast-fail saved ~{skipped_tests * (API_TIMEOUT * RETRY_ATTEMPTS):.0f}s by skipping retries\")\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Display download buttons\n",
    "    if export_files:\n",
    "        print(f\"\\n\\nüì• Download Reports:\")\n",
    "        print(f\"{'='*60}\")\n",
    "        for file_type, filepath in export_files:\n",
    "            create_download_button(filepath, f\"Download {file_type} Report\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nüí• UNHANDLED EXCEPTION in reporting: {str(e)}\")\n",
    "    stack = traceback.format_exc()\n",
    "    print(f\"   Stack trace:\\n{stack}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate timing charts and failure analysis visualizations\n",
    "try:\n",
    "    if GENERATE_CHARTS and (GLOBAL_STATE[\"timing_data\"] or GLOBAL_STATE[\"test_results\"]):\n",
    "        print(\"\\nüìä Generating performance charts and failure analysis...\\n\")\n",
    "        \n",
    "        has_timing_data = bool(GLOBAL_STATE[\"timing_data\"])\n",
    "        has_test_data = bool(GLOBAL_STATE[\"test_results\"])\n",
    "        \n",
    "        num_charts = 0\n",
    "        if has_timing_data:\n",
    "            num_charts += 2\n",
    "        if has_test_data:\n",
    "            num_charts += 2\n",
    "        \n",
    "        if num_charts == 0:\n",
    "            print(\"‚ö†Ô∏è  No data available for charting\")\n",
    "        else:\n",
    "            # Create figure\n",
    "            if num_charts == 4:\n",
    "                fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "                axes = [ax1, ax2, ax3, ax4]\n",
    "            elif num_charts == 3:\n",
    "                fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "                axes = [ax1, ax2, ax3]\n",
    "            elif num_charts == 2:\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "                axes = [ax1, ax2]\n",
    "            else:\n",
    "                fig, ax1 = plt.subplots(1, 1, figsize=(8, 6))\n",
    "                axes = [ax1]\n",
    "            \n",
    "            chart_idx = 0\n",
    "            \n",
    "            # Chart 1: Average latency per endpoint\n",
    "            if has_timing_data:\n",
    "                endpoints = list(GLOBAL_STATE[\"timing_data\"].keys())\n",
    "                avg_times = [sum(times)/len(times) for times in GLOBAL_STATE[\"timing_data\"].values()]\n",
    "                \n",
    "                axes[chart_idx].barh(endpoints, avg_times, color='steelblue')\n",
    "                axes[chart_idx].set_xlabel('Average Response Time (seconds)')\n",
    "                axes[chart_idx].set_title('Average Latency by Endpoint')\n",
    "                axes[chart_idx].grid(axis='x', alpha=0.3)\n",
    "                chart_idx += 1\n",
    "                \n",
    "                # Chart 2: Response time distribution\n",
    "                all_times = []\n",
    "                all_labels = []\n",
    "                for endpoint, times in GLOBAL_STATE[\"timing_data\"].items():\n",
    "                    all_times.extend(times)\n",
    "                    all_labels.extend([endpoint] * len(times))\n",
    "                \n",
    "                df_times = pd.DataFrame({'Endpoint': all_labels, 'Time': all_times})\n",
    "                sns.boxplot(data=df_times, y='Endpoint', x='Time', ax=axes[chart_idx])\n",
    "                axes[chart_idx].set_xlabel('Response Time (seconds)')\n",
    "                axes[chart_idx].set_title('Response Time Distribution')\n",
    "                axes[chart_idx].grid(axis='x', alpha=0.3)\n",
    "                chart_idx += 1\n",
    "            \n",
    "            # Chart 3: Error category pie chart\n",
    "            if has_test_data:\n",
    "                error_categories = {}\n",
    "                for result in GLOBAL_STATE[\"test_results\"]:\n",
    "                    if result.get(\"error_category\"):\n",
    "                        cat = result[\"error_category\"]\n",
    "                        error_categories[cat] = error_categories.get(cat, 0) + 1\n",
    "                \n",
    "                if error_categories and chart_idx < len(axes):\n",
    "                    labels = list(error_categories.keys())\n",
    "                    sizes = list(error_categories.values())\n",
    "                    colors = plt.cm.Set3(range(len(labels)))\n",
    "                    \n",
    "                    axes[chart_idx].pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "                    axes[chart_idx].set_title('Error Category Distribution')\n",
    "                    chart_idx += 1\n",
    "                \n",
    "                # Chart 4: Server health timeline\n",
    "                if GLOBAL_STATE[\"server_health_history\"] and chart_idx < len(axes):\n",
    "                    health_timeline = []\n",
    "                    timestamps = []\n",
    "                    \n",
    "                    for i, entry in enumerate(GLOBAL_STATE[\"server_health_history\"]):\n",
    "                        health = entry[\"health\"]\n",
    "                        health_value = {\n",
    "                            ServerHealth.ALIVE: 3,\n",
    "                            ServerHealth.DEGRADED: 2,\n",
    "                            ServerHealth.CRASHED: 1,\n",
    "                            ServerHealth.UNKNOWN: 0\n",
    "                        }.get(health, 0)\n",
    "                        health_timeline.append(health_value)\n",
    "                        timestamps.append(i)\n",
    "                    \n",
    "                    axes[chart_idx].plot(timestamps, health_timeline, marker='o', linewidth=2, markersize=6)\n",
    "                    axes[chart_idx].set_xlabel('Health Check Number')\n",
    "                    axes[chart_idx].set_ylabel('Server Health')\n",
    "                    axes[chart_idx].set_title('Server Health Timeline')\n",
    "                    axes[chart_idx].set_yticks([0, 1, 2, 3])\n",
    "                    axes[chart_idx].set_yticklabels(['Unknown', 'Crashed', 'Degraded', 'Alive'])\n",
    "                    axes[chart_idx].grid(alpha=0.3)\n",
    "                    \n",
    "                    crash_indices = [i for i, v in enumerate(health_timeline) if v == 1]\n",
    "                    if crash_indices:\n",
    "                        axes[chart_idx].scatter([timestamps[i] for i in crash_indices],\n",
    "                                               [health_timeline[i] for i in crash_indices],\n",
    "                                               color='red', s=200, alpha=0.5, zorder=5,\n",
    "                                               label='Crashes')\n",
    "                        axes[chart_idx].legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save chart\n",
    "            try:\n",
    "                chart_path = f\"{REPORT_OUTPUT_DIR}performance_chart_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
    "                plt.savefig(chart_path, dpi=150, bbox_inches='tight')\n",
    "                print(f\"‚úÖ Chart saved to: {chart_path}\")\n",
    "                plt.show()\n",
    "                \n",
    "                # Create download button for chart\n",
    "                print(f\"\\nüì• Download Chart:\")\n",
    "                print(f\"{'='*60}\")\n",
    "                create_download_button(chart_path, \"Download Performance Charts (PNG)\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Failed to save chart: {str(e)}\")\n",
    "                plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ Report generation complete!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nüí• UNHANDLED EXCEPTION in chart generation: {str(e)}\")\n",
    "    stack = traceback.format_exc()\n",
    "    print(f\"   Stack trace:\\n{stack}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "‚úÖ All tests completed with comprehensive error handling, fast-fail optimization, and one-click downloads!\n",
    "\n",
    "**üÜï New Features in This Version:**\n",
    "- ‚ö° **Fast-Fail Mode**: After first timeout, retries are skipped to save time (configurable via `ENABLE_FAST_FAIL`)\n",
    "- üì• **One-Click Downloads**: Click buttons to download reports directly from notebook (no Docker filesystem access needed)\n",
    "- üîÑ **DRY Code**: Test cells reduced from 50+ lines to 5-10 lines using `run_api_test()` utility\n",
    "- üìÅ **Accessible Reports**: Files saved to `/work/reports/` (inside container, Jupyter-accessible)\n",
    "- üíæ **Smart Storage**: Base64-encoded downloads work in any environment\n",
    "\n",
    "**Enhanced Features:**\n",
    "- üõ°Ô∏è **Error-Resistant Design**: Every test wrapped in try-except blocks to prevent cascading failures\n",
    "- üè• **Server Health Monitoring**: Automatic health checks before each test to detect server crashes\n",
    "- üîó **Dependency Tracking**: Tests automatically skip if prerequisites failed, preventing false positives\n",
    "- üìä **Comprehensive Diagnostics**: Error categorization, server health timeline, dependency chain analysis\n",
    "- üíª **System Information**: Captures CPU, memory, disk, platform info dynamically\n",
    "- üìà **Enhanced Reporting**: Failure analysis with actionable recommendations\n",
    "\n",
    "**Error Categories Tracked:**\n",
    "- `connection_error` - Cannot connect to server\n",
    "- `timeout` - Request exceeded timeout limit (triggers fast-fail mode)\n",
    "- `http_error` - HTTP error status (4xx, 5xx)\n",
    "- `server_crash` - Server completely unresponsive\n",
    "- `json_parse_error` - Invalid JSON response\n",
    "- `authentication_error` - Auth failures (401, 403)\n",
    "- `unknown` - Unhandled exception types\n",
    "\n",
    "**Artifacts Generated & Downloadable:**\n",
    "- üìã Test Results DataFrame (displayed in notebook)\n",
    "- üìÑ CSV Export: Clickable download button for spreadsheet analysis\n",
    "- üì¶ JSON Export: Clickable download button with full metadata (system info, server health timeline, stack traces)\n",
    "- üìä Performance Charts: Clickable download button for PNG charts (latency, distribution, error breakdown, health timeline)\n",
    "\n",
    "**Fast-Fail Performance:**\n",
    "- **Without fast-fail**: 7 timeout failures √ó 30s timeout √ó 3 retries = **~10 minutes wasted**\n",
    "- **With fast-fail**: 7 timeout failures √ó 30s timeout √ó 1 attempt = **~3.5 minutes**\n",
    "- **Time saved**: ~6.5 minutes (60% reduction)\n",
    "\n",
    "**Configuration Options:**\n",
    "- `BASE_URL`: Set to `http://nginx:8080` for Docker, `http://localhost:8080` for external\n",
    "- `BULK_SUBMISSION_COUNT`: Number of collections to create in bulk test (default: 100)\n",
    "- `API_TIMEOUT`: Request timeout in seconds (default: 30)\n",
    "- `RETRY_ATTEMPTS`: Max retries before giving up (default: 3, reduced to 1 in fast-fail mode)\n",
    "- `ENABLE_FAST_FAIL`: Enable smart retry skipping after timeouts (default: True)\n",
    "- `REPORT_OUTPUT_DIR`: Where to save reports (default: `/work/reports/`)\n",
    "\n",
    "**Global State Variables:**\n",
    "- `GLOBAL_STATE[\"api_key\"]` - API key for authentication\n",
    "- `GLOBAL_STATE[\"account_id\"]` - Account ID\n",
    "- `GLOBAL_STATE[\"collection_ids\"]` - List of created collection IDs\n",
    "- `GLOBAL_STATE[\"test_results\"]` - Detailed results for all tests\n",
    "- `GLOBAL_STATE[\"system_info\"]` - System/environment information\n",
    "- `GLOBAL_STATE[\"server_health_history\"]` - Timeline of server health checks\n",
    "- `GLOBAL_STATE[\"failed_dependencies\"]` - Set of tests that failed (blocking downstream tests)\n",
    "- `GLOBAL_STATE[\"fast_fail_mode\"]` - Whether fast-fail has been triggered\n",
    "- `GLOBAL_STATE[\"timeout_detected\"]` - Whether any timeouts occurred\n",
    "\n",
    "**Next Steps:**\n",
    "1. Review the detailed results and recommendations above\n",
    "2. **Click the download buttons** to get CSV/JSON/PNG reports\n",
    "3. Analyze performance charts to identify bottlenecks\n",
    "4. If server crashed/degraded, check container logs: `docker logs <container_name>`\n",
    "5. Adjust `BULK_SUBMISSION_COUNT` or `API_TIMEOUT` based on results\n",
    "6. Toggle `ENABLE_FAST_FAIL = False` if you want full retry behavior even after timeouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
